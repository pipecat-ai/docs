---
title: Introduction
description: "Learn about Pipecat and how to get started."
---

Pipecat is an open source Python framework for building voice and multimodal AI bots that can see, hear, and speak in real-time.

The framework orchestrates AI services, network transports, and audio processing to enable ultra-low latency conversations that feel natural and responsive. Build everything from simple voice assistants to complex multimodal applications that combine audio, video, images, and text.

Want to dive right in? Check out the Quickstart example to run your first Pipecat application.

<Card title="Quickstart" icon="rocket" href="/getting-started/quickstart">
  Build and run your first Pipecat application
</Card>

## What You Can Build

<CardGroup cols={2}>
  <Card
    title="Voice Assistants"
    icon="microphone"
    href="https://github.com/pipecat-ai/pipecat-examples/tree/main/simple-chatbot">
    Natural, real-time conversations with AI using speech recognition and
    synthesis
  </Card>

<Card
  title="Phone Agents"
  icon="phone"
  href="https://github.com/pipecat-ai/pipecat-examples/tree/main/patient-intake"
>
  Connect to your agent via phone for support, intake, and customer service
  interactions
</Card>

<Card
  title="Multimodal Apps"
  icon="layer-group"
  href="https://github.com/pipecat-ai/pipecat-examples/tree/main/moondream-chatbot"
>
  Applications that combine voice, video, images, and text for rich interactions
</Card>

<Card
  title="Creative Experiences"
  icon="wand-magic-sparkles"
  href="https://github.com/pipecat-ai/pipecat-examples/tree/main/storytelling-chatbot"
>
  Storytelling experiences and social companions that engage users
</Card>

<Card
  title="Interactive Games"
  icon="gamepad"
  href="https://github.com/pipecat-ai/pipecat-examples/tree/main/word-wrangler-gemini-live"
>
  Voice-controlled games and interactive experiences with real-time AI responses
</Card>

  <Card
    title="Conversation Flows"
    icon="diagram-project"
    href="https://github.com/pipecat-ai/pipecat-flows">
    Build structured conversations with Pipecat Flows to complete tasks and improve LLM accuracy
  </Card>
</CardGroup>

## How It Works

Pipecat orchestrates AI services in a **pipeline**, which is a series of processors that handle real-time audio, text, and video frames with ultra-low latency.

Here's what happens in a typical voice conversation:

1. **Transport** receives audio from the user (browser, phone, etc.)
2. **Speech Recognition** converts speech to text in real-time
3. **LLM** generates intelligent responses based on context
4. **Speech Synthesis** converts responses back to natural speech
5. **Transport** streams audio back to the user

In most cases, the entire round-trip interaction happens between 500-800ms, creating a natural conversation experience for the user.

The diagram below shows a typical voice assistant pipeline, where each step happens in real-time:

<img
  src="/images/pipecat-overview.png"
  alt="Pipecat Overview"
  className="rounded-lg"
/>

## Ready to Build?

The best way to understand Pipecat is to build with it. Start with our 5-minute quickstart to create your first voice AI bot.

<Card title="Quickstart" icon="rocket" href="/getting-started/quickstart">
  Build and run your first Pipecat application
</Card>

## Get Involved

<CardGroup cols={2}>

<Card
  title="Discord Community"
  icon="discord"
  iconType="duotone"
  href="https://discord.gg/pipecat"
>
  Connect with other developers, share your projects, and get support from the
  Pipecat team.
</Card>

<Card
  title="Pipecat GitHub repo"
  icon="github"
  iconType="duotone"
  href="https://github.com/pipecat-ai/pipecat"
>
  Explore the source code, open issues, and contribute to the project.
</Card>

</CardGroup>
