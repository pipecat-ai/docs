---
title: "Quickstart"
description: "Run your first Pipecat bot in under 5 minutes"
---

This quickstart guide will help you set up and run your first Pipecat application. You'll create a simple voice AI bot that you can talk to in real-time using your browser.

## Prerequisites

### Python 3.10+

Pipecat requires Python 3.10 or newer. Check your version with:

```bash
python --version
```

If you need to upgrade Python, we recommend using a version manager like `uv` or `pyenv`.

### AI Service API Keys

This quickstart uses three AI services working together in a pipeline. You'll need API keys from each service:

<CardGroup cols={3}>
  <Card
    title="Deepgram (STT)"
    icon="microphone"
    href="https://console.deepgram.com/signup"
  >
    Create an account and generate your API key for real-time
    speech recognition.
  </Card>

<Card
  title="OpenAI (LLM)"
  icon="brain"
  href="https://auth.openai.com/create-account"
>
  Create an account and generate an API key for intelligent conversation
  responses.
</Card>

  <Card
    title="Cartesia (TTS)"
    icon="volume-high"
    href="https://play.cartesia.ai/sign-up"
  >
    Sign up and generate your API key for natural voice
    synthesis.
  </Card>
</CardGroup>

Have these API keys ready. You'll add them to your environment file in the next section.

## Setup

1. Clone the quickstart repository

```bash
git clone https://github.com/pipecat-ai/pipecat-quickstart.git
cd pipecat-quickstart
```

### 2. Set up your environment

Create your environment file:

```bash
cp env.example .env
```

Open the `.env` file in your text editor and add your API keys:

```bash
DEEPGRAM_API_KEY=your_deepgram_api_key
OPENAI_API_KEY=your_openai_api_key
CARTESIA_API_KEY=your_cartesia_api_key
```

Replace each placeholder with your actual API key from the respective service.

### 3. Install dependencies

Set up your virtual environment and install dependencies:

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

<Tip>
  **Using `uv`?** Create and activate with: `uv venv && source
  .venv/bin/activate`, then install with: `uv pip install -r requirements.txt`
</Tip>

### 4. Run your bot

Now you're ready to run your bot! Start it with:

```bash
python bot.py
```

<Tip>**Using `uv`?** Run with: `uv run bot.py`</Tip>

You should see output similar to this:

```
ðŸš€ WebRTC server starting at http://localhost:7860/client
   Open this URL in your browser to connect!
```

### 5. Connect and test

Open your browser and navigate to **http://localhost:7860/client**. You'll see a `Connect` button in the upper righthand corner. Click `Connect` and allow microphone access when prompted by your browser.

You're now connected to your Pipecat bot! The bot will greet you and you can start talking to it. When you're finished, click `Disconnect` or close the browser tab to end the session. You can also stop the bot by pressing `Ctrl+C` in your terminal.

<Note>
  **First run timing**: The initial startup may take 10-15 seconds as Pipecat
  downloads required models like the Silero VAD (Voice Activity Detection)
  model. Subsequent runs will be much faster.
</Note>

## Understanding the Quickstart Bot

When you speak to your bot, here's the real-time pipeline that processes your conversation:

1. **Audio Capture**: Your browser captures microphone audio and sends it via WebRTC
2. **Voice Activity Detection**: Silero VAD detects when you start and stop speaking
3. **Speech Recognition**: Deepgram converts your speech to text in real-time
4. **Language Processing**: OpenAI's GPT model generates an intelligent response
5. **Speech Synthesis**: Cartesia converts the response text back to natural speech
6. **Audio Playback**: The generated audio streams back to your browser

Each step happens with minimal latency, typically completing the full round-trip in under one second.

### AI Services

Your bot uses three AI services, each configured with API keys from your `.env` file:

```python
# Create AI Services
stt = DeepgramSTTService(api_key=os.getenv("DEEPGRAM_API_KEY"))
tts = CartesiaTTSService(
    api_key=os.getenv("CARTESIA_API_KEY"),
    voice_id="71a7ad14-091c-4e8e-a314-022ece01c121",
)
llm = OpenAILLMService(api_key=os.getenv("OPENAI_API_KEY"))
```

Pipecat supports many different AI services. You can swap out Deepgram for Azure Speech, OpenAI for Anthropic, or Cartesia for ElevenLabs without changing the rest of your code.

See the [supported services documentation](https://docs.pipecat.ai/server/services/supported-services) for all available options.

### Context and Messages

Your bot maintains conversation history using a context object, enabling multi-turn interactions where the bot remembers what was said earlier.

The context is initialized with a system message that defines the bot's personality:

```python
# All messages use the OpenAI message format
messages = [
    {
        "role": "system",
        "content": "You are a friendly AI assistant. Respond naturally and keep your answers conversational.",
    },
]

context = OpenAILLMContext(messages)
context_aggregator = llm.create_context_aggregator(context)
```

The context aggregator automatically collects user messages (after speech-to-text) and assistant responses (after text-to-speech), maintaining the conversation flow without manual intervention.

### RTVI Protocol

When building web or mobile clients, you can use [Pipecat's client SDKs](https://docs.pipecat.ai/client/introduction) that communicate with your bot via the RTVI (Real-Time Voice Interaction) protocol. In our quickstart example, we initialize the RTVI processor to handle client-server messaging and events:

```python
rtvi = RTVIProcessor(config=RTVIConfig(config=[]))
```

### Pipeline Configuration

The core of your bot is a Pipeline that processes data through a series of processors:

```python
# Create the pipeline with the processors
pipeline = Pipeline([
    transport.input(),              # Receive audio from browser
    rtvi,                           # Protocol for client/server messaging and events
    stt,                            # Speech-to-text (Deepgram)
    context_aggregator.user(),      # Add user message to context
    llm,                            # Language model (OpenAI)
    tts,                            # Text-to-speech (Cartesia)
    transport.output(),             # Send audio back to browser
    context_aggregator.assistant(), # Add bot response to context
])
```

Data flows through the pipeline as "frames", objects containing audio, text, or other data types. The ordering is crucial: audio must be transcribed before it can be processed by the LLM, and text must be synthesized before it can be played back.

The pipeline is managed by a PipelineTask:

```python
# Create a PipelineTask to manage the pipeline execution
task = PipelineTask(
    pipeline,
    params=PipelineParams(
        enable_metrics=True,
        enable_usage_metrics=True,
    ),
    observers=[RTVIObserver(rtvi)],
)
```

The task handles pipeline execution, collects metrics, and manages RTVI events through observers.

### Event Handlers

Event handlers manage the bot's lifecycle and user interactions:

```python
# Event handler for when a client connects
@transport.event_handler("on_client_connected")
async def on_client_connected(transport, client):
    logger.info(f"Client connected")
    # Add a greeting message to the context
    messages.append({"role": "system", "content": "Say hello and briefly introduce yourself."})
    # Get a context frame and queue it for the task
    # This is what prompts the bot to start talking when the client connects
    await task.queue_frames([context_aggregator.user().get_context_frame()])

# Event handler for when a client disconnects
@transport.event_handler("on_client_disconnected")
async def on_client_disconnected(transport, client):
    logger.info(f"Client disconnected")
    # Cancel the task when the client disconnects
    # This stops the pipeline and all processors, cleaning up resources
    await task.cancel()
```

When a client connects, the bot adds a greeting instruction and queues a context frame to initiate the conversation. When disconnecting, it properly cancels the task to clean up resources.

### Running the Pipeline

Finally, the pipeline is executed by a PipelineRunner:

```python
# Create a PipelineRunner to run the task
runner = PipelineRunner(handle_sigint=False)

# Finally, run the task using the runner
# This will start the pipeline and begin processing frames
await runner.run(task)
```

The runner manages the pipeline's execution lifecycle. Note that `handle_sigint=False` because the main runner handles system signals.

### Bot Entry Point

The quickstart uses Pipecat's runner system:

```python
async def bot(session_args: SmallWebRTCSessionArguments):
    """Main bot entry point for the bot starter."""

    transport = SmallWebRTCTransport(
        params=TransportParams(
            audio_in_enabled=True,
            audio_out_enabled=True,
            vad_analyzer=SileroVADAnalyzer(),
        ),
        webrtc_connection=session_args.webrtc_connection,
    )

    await run_bot(transport)

if __name__ == "__main__":
    from pipecat.runner.run import main
    main()
```

This runner automatically handles WebRTC connection setup and management, making it easy to get started with minimal configuration.

<Tip>
  **Ready for production?** This bot pattern is compatible with Pipecat Cloud,
  meaning you can deploy your bot without any code changes.
</Tip>

## Troubleshooting

- **Browser permissions**: Make sure to allow microphone access when prompted by your browser.
- **Connection issues**: If the WebRTC connection fails, first try a different browser. If that fails, make sure you don't have a VPN or firewall rules blocking traffic. WebRTC uses UDP to communicate.
- **Audio issues**: Check that your microphone and speakers are working and not muted.

## Next Steps

Now that you have your first Pipecat bot running, you can explore further:

- **Customize your bot**: Edit the system prompt in `bot.py` to change your agent's personality and behavior. Try different roles like a helpful assistant, creative writer, or domain expert.
- **Learn client/server architecture**: Try the [Client/Server Web example](https://github.com/pipecat-ai/pipecat-quickstart-client-server) to learn how to build custom web interfaces
- **Connect to a phone**: Explore the [Phone Bot Twilio example](https://github.com/pipecat-ai/pipecat-quickstart-phone-bot) to make your bot callable
- **Join the community**: Connect with other Pipecat developers on [Discord](https://discord.gg/pipecat) to share your projects, get help, and see what others are building.
