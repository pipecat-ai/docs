---
title: "Smart Turn Detection"
description: "Advanced conversational turn detection"
---

## Overview

Smart Turn Detection uses an advanced machine learning model to determine when a user has finished speaking and your bot should respond. Unlike basic Voice Activity Detection (VAD) which only detects speech vs. non-speech, Smart Turn Detection recognizes natural conversational cues like intonation patterns and linguistic signals for more natural conversations.

<CardGroup cols={2}>
  <Card
    title="GitHub Repository"
    icon="github"
    href="https://github.com/pipecat-ai/smart-turn"
  >
    Open source model for conversational turn detection
  </Card>
  <Card
    title="Model weights"
    icon="face-smiling-hands"
    href="https://huggingface.co/pipecat-ai/smart-turn-v3/tree/main"
  >
    ONNX weights file for Smart Turn v3
  </Card>
</CardGroup>

## Key Benefits

- **Natural conversations**: More human-like turn-taking patterns
- **Free to use**: The model is fully open source
- **Scalable**: Smart Turn v3 supports fast CPU inference directly inside your Pipecat Cloud instance

## Quick Start

To enable Smart Turn Detection in your Pipecat Cloud bot, add the `LocalSmartTurnAnalyzerV3` analyzer to your transport configuration.

The model weights are bundled with Pipecat, so there's no need to download them separately.

```python
import aiohttp
from pipecat.audio.turn.smart_turn.local_smart_turn_v3 import LocalSmartTurnAnalyzerV3
from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.audio.vad.vad_analyzer import VADParams
from pipecat.transports.services.daily import DailyParams, DailyTransport

async def main(room_url: str, token: str):
    async with aiohttp.ClientSession() as session:
        transport = DailyTransport(
            room_url,
            token,
            "Voice AI Bot",
            DailyParams(
                audio_in_enabled=True,
                audio_out_enabled=True,
                # Set VAD to 0.2 seconds for optimal Smart Turn performance
                vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.2)),
                # Enable local Smart Turn inference using the weights bundled with Pipecat
                turn_analyzer=LocalSmartTurnAnalyzerV3(),
            ),
        )

        # Continue with your pipeline setup...
```

<Tip>
  Smart Turn Detection requires VAD to be enabled with `stop_secs=0.2`. This
  value mimics the training data and allows Smart Turn to dynamically adjust
  timing based on the model's predictions.
</Tip>

## How It Works

1. **Audio Analysis**: The system continuously analyzes incoming audio for speech patterns
2. **VAD Processing**: Voice Activity Detection segments audio into speech and silence
3. **Turn Classification**: When VAD detects a pause, the ML model analyzes the speech segment for natural completion cues
4. **Smart Response**: The model determines if the turn is complete or if the user is likely to continue speaking

## Training Data Collection

The smart-turn model is trained on real conversational data collected through these applications. Help us improve the model by contributing your own data or classifying existing data:

<CardGroup cols={2}>
  <Card
    title="Data Collector"
    icon="microphone"
    href="https://turn-training.pipecat.ai/"
  >
    Contribute conversational data to improve the model
  </Card>
  <Card
    title="Data Classifier"
    icon="check-circle"
    href="https://smart-turn-dataset.pipecat.ai/"
  >
    Help classify turn completion patterns in conversations
  </Card>
</CardGroup>


## More information

For more details on Smart Turn, see the following links:

<CardGroup cols={2}>
  <Card
    title="Smart Turn Overview"
    href="../../../server/utilities/smart-turn/smart-turn-overview"
  >
    More details about the Pipecat Smart Turn integration
  </Card>
</CardGroup>
