---
title: "OpenAI"
description: "Large Language Model services using OpenAI's chat completion API"
---

## Overview

`OpenAILLMService` provides chat completion capabilities using OpenAI's API, supporting streaming responses, function calling, vision input, and advanced context management for conversational AI applications with state-of-the-art language models.

<CardGroup cols={2}>
  <Card
    title="OpenAI LLM API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.openai.base_llm.html"
  >
    Pipecat's API methods for OpenAI integration
  </Card>
  <Card
    title="Example Implementation"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/14-function-calling.py"
  >
    Function calling example with weather API
  </Card>
  <Card
    title="OpenAI Documentation"
    icon="book"
    href="https://platform.openai.com/docs/api-reference/chat"
  >
    Official OpenAI API documentation
  </Card>
  <Card
    title="OpenAI Platform"
    icon="microphone"
    href="https://platform.openai.com/api-keys"
  >
    Access models and manage API keys
  </Card>
</CardGroup>

## Installation

To use OpenAI services, install the required dependencies:

```bash
pip install "pipecat-ai[openai]"
```

## Prerequisites

### OpenAI Account Setup

Before using OpenAI LLM services, you need:

1. **OpenAI Account**: Sign up at [OpenAI Platform](https://platform.openai.com/)
2. **API Key**: Generate an API key from your account dashboard
3. **Model Selection**: Choose from available models (GPT-4o, GPT-4, GPT-3.5-turbo, etc.)
4. **Usage Limits**: Set up billing and usage limits as needed

### Required Environment Variables

- `OPENAI_API_KEY`: Your OpenAI API key for authentication
