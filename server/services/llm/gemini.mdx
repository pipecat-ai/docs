---
title: "Google Gemini"
description: "Large Language Model service implementation using Google's Gemini API"
---

## Overview

`GoogleLLMService` provides integration with Google's Gemini models, supporting streaming responses, function calling, and multimodal inputs. It includes specialized context handling for Google's message format while maintaining compatibility with OpenAI-style contexts.

<CardGroup cols={2}>
  <Card
    title="Gemini LLM API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.google.llm.html"
  >
    Pipecat's API methods for Google Gemini integration
  </Card>
  <Card
    title="Example Implementation"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/14e-function-calling-google.py"
  >
    Complete example with function calling
  </Card>
  <Card
    title="Gemini Documentation"
    icon="book"
    href="https://ai.google.dev/gemini-api/docs"
  >
    Official Google Gemini API documentation and features
  </Card>
  <Card
    title="Google AI Studio"
    icon="microphone"
    href="https://aistudio.google.com/"
  >
    Access Gemini models and manage API keys
  </Card>
</CardGroup>

## Installation

To use Google Gemini services, install the required dependencies:

```bash
pip install "pipecat-ai[google]"
```

## Prerequisites

### Google Gemini Setup

Before using Google Gemini LLM services, you need:

1. **Google Account**: Sign up at [Google AI Studio](https://aistudio.google.com/)
2. **API Key**: Generate a Gemini API key from AI Studio
3. **Model Selection**: Choose from available Gemini models (Gemini 1.5 Pro, Flash, etc.)

### Required Environment Variables

- `GOOGLE_API_KEY`: Your Google Gemini API key for authentication
