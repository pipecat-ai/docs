---
title: "Google Vertex AI"
description: "LLM service implementation using Google's Vertex AI with OpenAI-compatible interface"
---

## Overview

`GoogleVertexLLMService` provides access to Google's language models through Vertex AI while maintaining an OpenAI-compatible interface. It inherits from `OpenAILLMService` and supports all OpenAI features while connecting to Google's enterprise AI services with enhanced security and compliance.

<CardGroup cols={2}>
  <Card
    title="Vertex AI LLM API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.google.llm_vertex.html"
  >
    Pipecat's API methods for Google Vertex AI integration
  </Card>
  <Card
    title="Example Implementation"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/14p-function-calling-gemini-vertex-ai.py"
  >
    Browse examples using Vertex AI models
  </Card>
  <Card
    title="Vertex AI Documentation"
    icon="book"
    href="https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference"
  >
    Official Google Vertex AI documentation
  </Card>
  <Card
    title="Google Cloud Console"
    icon="microphone"
    href="https://console.cloud.google.com/vertex-ai"
  >
    Access Vertex AI and manage credentials
  </Card>
</CardGroup>

## Installation

To use Google Vertex AI services, install the required dependencies:

```bash
pip install "pipecat-ai[google]"
```

## Prerequisites

### Google Cloud Setup

Before using Google Vertex AI LLM services, you need:

1. **Google Cloud Account**: Sign up at [Google Cloud Console](https://console.cloud.google.com/)
2. **Project Setup**: Create a project and enable the Vertex AI API
3. **Service Account**: Create a service account with Vertex AI permissions
4. **Authentication**: Set up credentials via service account key or Application Default Credentials

### Required Environment Variables

- `GOOGLE_APPLICATION_CREDENTIALS`: Path to your service account key file (recommended)
- Or use Application Default Credentials for cloud deployments

## Configuration

<ParamField path="credentials" type="str" default="None">
  JSON string of Google service account credentials for authentication.
</ParamField>

<ParamField path="credentials_path" type="str" default="None">
  Path to the service account JSON key file. Alternative to providing credentials as a string.
</ParamField>

<ParamField path="project_id" type="str" required>
  Google Cloud project ID.
</ParamField>

<ParamField path="location" type="str" default="us-east4">
  GCP region for the Vertex AI endpoint (e.g., `"us-east4"`, `"us-central1"`).
</ParamField>

<ParamField path="model" type="str" default="gemini-2.5-flash">
  Model identifier to use.
</ParamField>

<ParamField path="params" type="InputParams" default="None">
  Runtime-configurable model settings. See [Google Gemini](/server/services/llm/gemini) for InputParams details.
</ParamField>

<ParamField path="system_instruction" type="str" default="None">
  System instruction/prompt for the model.
</ParamField>

<ParamField path="tools" type="list" default="None">
  List of available tools/functions for the model.
</ParamField>

<ParamField path="tool_config" type="dict" default="None">
  Configuration for tool usage behavior.
</ParamField>

<ParamField path="http_options" type="HttpOptions" default="None">
  HTTP options for the Google AI client.
</ParamField>

## Usage

### Basic Setup

```python
import os
from pipecat.services.google import GoogleVertexLLMService

llm = GoogleVertexLLMService(
    credentials_path=os.getenv("GOOGLE_APPLICATION_CREDENTIALS"),
    project_id="my-gcp-project",
    location="us-east4",
    model="gemini-2.5-flash",
)
```

### With Credentials JSON String

```python
from pipecat.services.google import GoogleVertexLLMService

llm = GoogleVertexLLMService(
    credentials=os.getenv("GOOGLE_CREDENTIALS_JSON"),
    project_id="my-gcp-project",
    location="us-central1",
    model="gemini-2.5-flash",
    params=GoogleVertexLLMService.InputParams(
        temperature=0.7,
        top_p=0.9,
    ),
)
```

### With Application Default Credentials

```python
from pipecat.services.google import GoogleVertexLLMService

# Uses ADC when neither credentials nor credentials_path is provided
llm = GoogleVertexLLMService(
    project_id="my-gcp-project",
    location="us-east4",
    model="gemini-2.5-flash",
)
```

## Notes

- This service does **not** accept an `api_key` parameter. Use `credentials`, `credentials_path`, or Application Default Credentials instead.
- `GoogleVertexLLMService` extends `GoogleLLMService` (not `OpenAILLMService` directly) and uses the Google AI Python SDK with Vertex AI authentication.
- Authentication supports three methods: direct JSON credentials string, path to a service account key file, or Application Default Credentials (ADC).
- The `project_id` parameter is required. If `location` is not provided, it defaults to `"us-east4"`.
