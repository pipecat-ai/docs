---
title: "NVIDIA NIM"
description: "LLM service implementation using NVIDIA's NIM (NVIDIA Inference Microservice) API with OpenAI-compatible interface"
---

## Overview

`NvidiaLLMService` provides access to NVIDIA's NIM language models through an OpenAI-compatible interface. It inherits from `OpenAILLMService` and supports streaming responses, function calling, and context management, with special handling for NVIDIA's incremental token reporting and enterprise deployment.

<CardGroup cols={2}>
  <Card
    title="NVIDIA NIM LLM API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.nim.llm.html"
  >
    Pipecat's API methods for NVIDIA NIM integration
  </Card>
  <Card
    title="Example Implementation"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/14j-function-calling-nim.py"
  >
    Complete example with function calling
  </Card>
  <Card
    title="NVIDIA NIM Documentation"
    icon="book"
    href="https://docs.nvidia.com/nim/"
  >
    Official NVIDIA NIM documentation and setup
  </Card>
  <Card
    title="NVIDIA Developer Portal"
    icon="microphone"
    href="https://developer.nvidia.com/"
  >
    Access NIM services and manage API keys
  </Card>
</CardGroup>

## Installation

To use NVIDIA NIM services, install the required dependencies:

```bash
pip install "pipecat-ai[nvidia]"
```

## Prerequisites

### NVIDIA NIM Setup

Before using NVIDIA NIM LLM services, you need:

1. **NVIDIA Developer Account**: Sign up at [NVIDIA Developer Portal](https://developer.nvidia.com/)
2. **API Key**: Generate an NVIDIA API key for NIM services
3. **Model Selection**: Choose from available NIM-hosted models
4. **Enterprise Setup**: Configure NIM for on-premises deployment if needed

### Required Environment Variables

- `NVIDIA_API_KEY`: Your NVIDIA API key for authentication
