---
title: "Perplexity"
description: "LLM service implementation using Perplexity's API with OpenAI-compatible interface"
---

## Overview

`PerplexityLLMService` provides access to Perplexity's language models through an OpenAI-compatible interface. It inherits from `OpenAILLMService` and supports streaming responses and context management, with special handling for Perplexity's incremental token reporting and built-in internet search capabilities.

<CardGroup cols={2}>
  <Card
    title="Perplexity LLM API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.perplexity.llm.html"
  >
    Pipecat's API methods for Perplexity integration
  </Card>
  <Card
    title="Example Implementation"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/14n-function-calling-perplexity.py"
  >
    Complete example with search capabilities
  </Card>
  <Card
    title="Perplexity Documentation"
    icon="book"
    href="https://docs.perplexity.ai/api-reference/chat-completions-post"
  >
    Official Perplexity API documentation and features
  </Card>
  <Card
    title="Perplexity Platform"
    icon="microphone"
    href="https://www.perplexity.ai/"
  >
    Access search-enhanced models and API keys
  </Card>
</CardGroup>

## Installation

To use Perplexity services, install the required dependencies:

```bash
pip install "pipecat-ai[perplexity]"
```

## Prerequisites

### Perplexity Account Setup

Before using Perplexity LLM services, you need:

1. **Perplexity Account**: Sign up at [Perplexity](https://www.perplexity.ai/)
2. **API Key**: Generate an API key from your account dashboard
3. **Model Selection**: Choose from available models with built-in search capabilities

### Required Environment Variables

- `PERPLEXITY_API_KEY`: Your Perplexity API key for authentication

<Note>
  Unlike other LLM services, Perplexity does not support function calling.
  Instead, they offer native internet search built in without requiring special
  function calls.
</Note>

## Configuration

<ParamField path="api_key" type="str" required>
  Perplexity API key for authentication.
</ParamField>

<ParamField path="base_url" type="str" default="https://api.perplexity.ai">
  Base URL for Perplexity API endpoint.
</ParamField>

<ParamField path="model" type="str" default="sonar">
  Model identifier to use.
</ParamField>

### InputParams

This service uses the same input parameters as `OpenAILLMService`. See [OpenAI LLM](/server/services/llm/openai#inputparams) for details.

## Usage

### Basic Setup

```python
import os
from pipecat.services.perplexity import PerplexityLLMService

llm = PerplexityLLMService(
    api_key=os.getenv("PERPLEXITY_API_KEY"),
    model="sonar",
)
```

### With Custom Parameters

```python
from pipecat.services.perplexity import PerplexityLLMService

llm = PerplexityLLMService(
    api_key=os.getenv("PERPLEXITY_API_KEY"),
    model="sonar",
    params=PerplexityLLMService.InputParams(
        temperature=0.7,
        top_p=0.9,
        max_tokens=1024,
    ),
)
```

## Notes

- Perplexity does not support function calling or tools. The service only sends messages to the API, without tool definitions.
- Perplexity uses incremental token reporting. The service accumulates token usage metrics during processing and reports the final totals at the end of each request.
- Perplexity models have built-in internet search capabilities, providing up-to-date information without requiring additional tool configuration.
