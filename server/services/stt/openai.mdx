---
title: "OpenAI"
description: "Speech-to-text service implementation using OpenAI's Speech-to-Text APIs"
---

## Overview

`OpenAISTTService` provides high-accuracy speech recognition using OpenAI's advanced transcription models, including the latest GPT-4o transcription model and the proven Whisper API. It uses Voice Activity Detection (VAD) to efficiently process speech segments with superior accuracy and context understanding.

<CardGroup cols={2}>
  <Card
    title="OpenAI STT API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.openai.stt.html"
  >
    Pipecat's API methods for OpenAI STT integration
  </Card>
  <Card
    title="Example Implementation"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/07g-interruptible-openai.py"
  >
    Complete example with OpenAI ecosystem integration
  </Card>
  <Card
    title="OpenAI Documentation"
    icon="book"
    href="https://platform.openai.com/docs/api-reference/audio/createTranscription"
  >
    Official OpenAI transcription documentation and features
  </Card>
  <Card
    title="OpenAI Platform"
    icon="microphone"
    href="https://platform.openai.com/api-keys"
  >
    Access API keys and transcription models
  </Card>
</CardGroup>

## Installation

To use OpenAI services, install the required dependency:

```bash
pip install "pipecat-ai[openai]"
```

## Prerequisites

### OpenAI Account Setup

Before using OpenAI STT services, you need:

1. **OpenAI Account**: Sign up at [OpenAI Platform](https://platform.openai.com/)
2. **API Key**: Generate an API key from your account dashboard
3. **Model Access**: Ensure access to Whisper and GPT-4o transcription models

### Required Environment Variables

- `OPENAI_API_KEY`: Your OpenAI API key for authentication
