---
title: "Deepgram"
description: "Speech-to-text service implementations using Deepgram's real-time transcription and Flux APIs"
---

## Overview

Deepgram provides three STT service implementations:

- `DeepgramSTTService` for real-time speech recognition using Deepgram's standard WebSocket API with support for interim results, language detection, and voice activity detection (VAD)
- `DeepgramFluxSTTService` for advanced conversational AI with Flux capabilities including intelligent turn detection, eager end-of-turn events, and enhanced speech processing for improved response timing
- `DeepgramSageMakerSTTService` for real-time speech recognition using Deepgram models deployed on AWS SageMaker endpoints via HTTP/2 bidirectional streaming

<Note>
  Since Deepgram Flux provides its own user turn start and end detection, you
  should use `ExternalUserTurnStrategies` to let Flux handle turn management.
  See [User Turn
  Strategies](/server/utilities/turn-management/user-turn-strategies) for
  configuration details.
</Note>

<CardGroup cols={2}>
  <Card
    title="Deepgram STT API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.deepgram.stt.html"
  >
    Pipecat's API methods for standard Deepgram STT
  </Card>
  <Card
    title="Deepgram Flux API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.deepgram.flux.stt.html"
  >
    Pipecat's API methods for Deepgram Flux STT
  </Card>
  <Card
    title="Standard STT Example"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/07c-interruptible-deepgram.py"
  >
    Complete example with standard Deepgram STT
  </Card>
  <Card
    title="Flux STT Example"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/07c-interruptible-deepgram-flux.py"
  >
    Complete example with Deepgram Flux STT
  </Card>
  <Card
    title="SageMaker Example"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/07c-interruptible-deepgram-sagemaker.py"
  >
    Complete example with Deepgram on SageMaker
  </Card>
  <Card
    title="Deepgram Documentation"
    icon="book"
    href="https://developers.deepgram.com/docs/pre-recorded-audio"
  >
    Official Deepgram documentation and features
  </Card>
  <Card
    title="Deepgram Console"
    icon="microphone"
    href="https://console.deepgram.com/signup"
  >
    Access API keys and transcription models
  </Card>
</CardGroup>

## Installation

To use Deepgram STT services, install the required dependencies:

```bash
pip install "pipecat-ai[deepgram]"
```

For the SageMaker variant, install both the Deepgram and SageMaker dependencies:

```bash
pip install "pipecat-ai[deepgram,sagemaker]"
```

## Prerequisites

### Deepgram Account Setup

Before using `DeepgramSTTService` or `DeepgramFluxSTTService`, you need:

1. **Deepgram Account**: Sign up at [Deepgram Console](https://console.deepgram.com/signup)
2. **API Key**: Generate an API key from your console dashboard
3. **Model Selection**: Choose from available transcription models and features

### Required Environment Variables

- `DEEPGRAM_API_KEY`: Your Deepgram API key for authentication

### AWS SageMaker Setup

Before using `DeepgramSageMakerSTTService`, you need:

1. **AWS Account**: With credentials configured (via environment variables, AWS CLI, or instance metadata)
2. **SageMaker Endpoint**: A deployed SageMaker endpoint with a [Deepgram model](https://developers.deepgram.com/docs/deploy-amazon-sagemaker)
3. **Deepgram SDK**: The Deepgram SDK is required for `LiveOptions` configuration

## Configuration

### DeepgramSTTService

<ParamField path="api_key" type="str" required>
  Deepgram API key for authentication.
</ParamField>

<ParamField path="base_url" type="str" default='""'>
  Custom Deepgram API base URL. Leave empty for the default endpoint.
</ParamField>

<ParamField path="sample_rate" type="int" default="None">
  Audio sample rate in Hz. When `None`, uses the value from `live_options` or
  the pipeline's configured sample rate.
</ParamField>

<ParamField path="live_options" type="LiveOptions" default="None">
  Deepgram `LiveOptions` for detailed configuration. When provided, these
  settings are merged with the defaults. See [Deepgram
  LiveOptions](https://developers.deepgram.com/docs/live-streaming-audio#live-streaming-options)
  for available options.
</ParamField>

<ParamField path="addons" type="Dict" default="None">
  Additional Deepgram features to enable.
</ParamField>

<ParamField path="ttfs_p99_latency" type="float" default="DEEPGRAM_TTFS_P99">
  P99 latency from speech end to final transcript in seconds. Override for your
  deployment.
</ParamField>

The default `LiveOptions` are:

| Option             | Default            | Description                                         |
| ------------------ | ------------------ | --------------------------------------------------- |
| `encoding`         | `"linear16"`       | Audio encoding format.                              |
| `language`         | `Language.EN`      | Recognition language.                               |
| `model`            | `"nova-3-general"` | Deepgram model to use.                              |
| `channels`         | `1`                | Number of audio channels.                           |
| `interim_results`  | `True`             | Stream partial recognition results.                 |
| `smart_format`     | `False`            | Apply smart formatting.                             |
| `punctuate`        | `True`             | Add punctuation to transcripts.                     |
| `profanity_filter` | `True`             | Filter profanity from transcripts.                  |
| `vad_events`       | `False`            | Enable Deepgram's built-in VAD events (deprecated). |

### DeepgramFluxSTTService

<ParamField path="api_key" type="str" required>
  Deepgram API key for authentication.
</ParamField>

<ParamField path="url" type="str" default="wss://api.deepgram.com/v2/listen">
  WebSocket URL for the Deepgram Flux API.
</ParamField>

<ParamField path="sample_rate" type="int" default="None">
  Audio sample rate in Hz. When `None`, uses the pipeline's configured sample
  rate.
</ParamField>

<ParamField path="model" type="str" default="flux-general-en">
  Deepgram Flux model to use for transcription.
</ParamField>

<ParamField path="flux_encoding" type="str" default="linear16">
  Audio encoding format required by the Flux API. Must be `"linear16"`.
</ParamField>

<ParamField path="params" type="InputParams" default="None">
  Configuration parameters for the Flux API. See [Flux
  InputParams](#flux-inputparams) below.
</ParamField>

<ParamField path="should_interrupt" type="bool" default="True">
  Whether the bot should be interrupted when Flux detects user speech.
</ParamField>

### Flux InputParams

Parameters passed via the `params` constructor argument for `DeepgramFluxSTTService`.

| Parameter             | Type    | Default | Description                                                                                                                                               |
| --------------------- | ------- | ------- | --------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `eager_eot_threshold` | `float` | `None`  | EagerEndOfTurn threshold. Lower values trigger faster responses with more LLM calls; higher values are more conservative. `None` disables EagerEndOfTurn. |
| `eot_threshold`       | `float` | `None`  | End-of-turn confidence threshold (default 0.7). Lower = faster turn endings.                                                                              |
| `eot_timeout_ms`      | `int`   | `None`  | Time in ms after speech to finish a turn regardless of confidence (default 5000).                                                                         |
| `keyterm`             | `list`  | `[]`    | Key terms to boost recognition accuracy for specialized terminology.                                                                                      |
| `mip_opt_out`         | `bool`  | `None`  | Opt out of Deepgram's Model Improvement Program.                                                                                                          |
| `tag`                 | `list`  | `[]`    | Tags for request identification during usage reporting.                                                                                                   |
| `min_confidence`      | `float` | `None`  | Minimum average confidence required to produce a `TranscriptionFrame`.                                                                                    |

### DeepgramSageMakerSTTService

<ParamField path="endpoint_name" type="str" required>
  Name of the SageMaker endpoint with Deepgram model deployed.
</ParamField>

<ParamField path="region" type="str" required>
  AWS region where the SageMaker endpoint is deployed (e.g., `"us-east-2"`).
</ParamField>

<ParamField path="sample_rate" type="int" default="None">
  Audio sample rate in Hz. When `None`, uses the value from `live_options` or
  the pipeline's configured sample rate.
</ParamField>

<ParamField path="live_options" type="LiveOptions" default="None">
  Deepgram `LiveOptions` for detailed configuration. When provided, these
  settings are merged with the defaults. See [Deepgram
  LiveOptions](https://developers.deepgram.com/docs/live-streaming-audio#live-streaming-options)
  for available options.
</ParamField>

<ParamField path="ttfs_p99_latency" type="float" default="DEEPGRAM_SAGEMAKER_TTFS_P99">
  P99 latency from speech end to final transcript in seconds. Override for your
  deployment.
</ParamField>

The default `LiveOptions` for the SageMaker variant are:

| Option            | Default        | Description                         |
| ----------------- | -------------- | ----------------------------------- |
| `encoding`        | `"linear16"`   | Audio encoding format.              |
| `language`        | `Language.EN`  | Recognition language.               |
| `model`           | `"nova-3"`     | Deepgram model to use.              |
| `channels`        | `1`            | Number of audio channels.           |
| `interim_results` | `True`         | Stream partial recognition results. |
| `punctuate`       | `True`         | Add punctuation to transcripts.     |

## Usage

### Basic DeepgramSTTService

```python
from pipecat.services.deepgram import DeepgramSTTService

stt = DeepgramSTTService(
    api_key=os.getenv("DEEPGRAM_API_KEY"),
)
```

### With Custom LiveOptions

```python
from deepgram import LiveOptions
from pipecat.services.deepgram import DeepgramSTTService

stt = DeepgramSTTService(
    api_key=os.getenv("DEEPGRAM_API_KEY"),
    live_options=LiveOptions(
        model="nova-3-general",
        language="es",
        punctuate=True,
        smart_format=True,
    ),
)
```

### DeepgramFluxSTTService

```python
from pipecat.services.deepgram.flux import DeepgramFluxSTTService

stt = DeepgramFluxSTTService(
    api_key=os.getenv("DEEPGRAM_API_KEY"),
)
```

### Flux with EagerEndOfTurn

```python
from pipecat.services.deepgram.flux import DeepgramFluxSTTService

stt = DeepgramFluxSTTService(
    api_key=os.getenv("DEEPGRAM_API_KEY"),
    params=DeepgramFluxSTTService.InputParams(
        eager_eot_threshold=0.5,
        eot_threshold=0.8,
        keyterm=["Pipecat", "Deepgram"],
    ),
)
```

### SageMaker Service

```python
from deepgram import LiveOptions
from pipecat.services.deepgram.stt_sagemaker import DeepgramSageMakerSTTService

stt = DeepgramSageMakerSTTService(
    endpoint_name=os.getenv("SAGEMAKER_STT_ENDPOINT_NAME"),
    region=os.getenv("AWS_REGION"),
    live_options=LiveOptions(
        model="nova-3",
        language="en",
        interim_results=True,
        punctuate=True,
    ),
)
```

## Notes

- **Finalize on VAD stop**: When the pipeline's VAD detects the user has stopped speaking, `DeepgramSTTService` and `DeepgramSageMakerSTTService` send a [finalize](https://developers.deepgram.com/docs/finalize) request to Deepgram for faster final transcript delivery.
- **Flux turn management**: `DeepgramFluxSTTService` provides its own turn detection via `StartOfTurn`/`EndOfTurn` events and broadcasts `UserStartedSpeakingFrame`/`UserStoppedSpeakingFrame` directly. Use `ExternalUserTurnStrategies` to avoid conflicting VAD-based turn management.
- **EagerEndOfTurn**: In Flux, enabling `eager_eot_threshold` provides faster response times by predicting end-of-turn before it is confirmed. EagerEndOfTurn transcripts are pushed as `InterimTranscriptionFrame`s. If the user resumes speaking, a `TurnResumed` event is fired.
- **Deprecated vad_events**: The `vad_events` option in standard `DeepgramSTTService` is deprecated. Use Silero VAD instead.
- **SageMaker deployment**: The SageMaker service requires a Deepgram model deployed to an AWS SageMaker endpoint. See the [Deepgram SageMaker deployment guide](https://developers.deepgram.com/docs/deploy-amazon-sagemaker) for setup instructions.
- **SageMaker keepalive**: The SageMaker service automatically sends KeepAlive messages every 5 seconds to maintain the connection during periods of silence.

## Event Handlers

All three services support the standard [service connection events](/server/utilities/service-events) (`on_connected`, `on_disconnected`, `on_connection_error`). Additionally, `DeepgramSTTService` and `DeepgramFluxSTTService` provide service-specific events:

### DeepgramSTTService

| Event               | Description                           |
| ------------------- | ------------------------------------- |
| `on_speech_started` | Speech detected in the audio stream   |
| `on_utterance_end`  | End of utterance detected by Deepgram |

```python
@stt.event_handler("on_speech_started")
async def on_speech_started(service):
    print("User started speaking")

@stt.event_handler("on_utterance_end")
async def on_utterance_end(service):
    print("Utterance ended")
```

### DeepgramFluxSTTService

Deepgram Flux provides turn-level events for more granular conversation tracking:

| Event                  | Description                          |
| ---------------------- | ------------------------------------ |
| `on_start_of_turn`     | Start of a new turn detected         |
| `on_turn_resumed`      | A previously paused turn has resumed |
| `on_end_of_turn`       | End of turn detected                 |
| `on_eager_end_of_turn` | Early end-of-turn prediction         |
| `on_update`            | Transcript updated                   |

```python
@stt.event_handler("on_start_of_turn")
async def on_start_of_turn(service, transcript):
    print(f"Turn started: {transcript}")

@stt.event_handler("on_end_of_turn")
async def on_end_of_turn(service, transcript):
    print(f"Turn ended: {transcript}")

@stt.event_handler("on_eager_end_of_turn")
async def on_eager_end_of_turn(service, transcript):
    print(f"Early end-of-turn prediction: {transcript}")
```

Turn events receive `(service, transcript)` where `transcript` is the current transcript text. The `on_turn_resumed` event receives only `(service)`.
