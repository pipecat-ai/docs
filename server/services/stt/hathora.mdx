---
title: "Hathora"
description: "Speech-to-text service implementations hosted on Hathora"
---

## Overview

Hathora is a hosting provider for several models for voice AI, which can be utilized under the single `HathoraSTTService`.

<CardGroup cols={2}>
  <Card
    title="Hathora STT API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.hahotra.stt.html"
  >
    Pipecat's API methods for Hathora-hosted STT models
  </Card>
  <Card
    title="Example Implementation"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/07ag-interruptible-hathora.py"
  >
    Complete example using Hathora-hosted models
  </Card>
  <Card
    title="Hathora Models Documentation"
    icon="book"
    href="https://models.hathora.dev/"
  >
    Official Hathora documentation and features
  </Card>
</CardGroup>

## Installation

To use Hathora services, install the required dependencies:

```bash
pip install "pipecat-ai[hathora]"
```

## Prerequisites

### Hathora Account Setup

Before using Hathora STT services, you need:

1. **Hathora Account**: Sign up at [Hathora Models Console](https://models.hathora.dev/)
1. **API Key**: Generate an API token from your [Tokens page](https://models.hathora.dev/tokens)

### Hathora Model Specifier

The `HathoraSTTService` accepts a `model: str` parameter which corresponds to the model you would like to use.

You can find available specifiers [here](https://models.hathora.dev/)

## Configuration

### HathoraSTTService

<ParamField path="model" type="str" required>
  Model to use for transcription. Find available models at
  [models.hathora.dev](https://models.hathora.dev).
</ParamField>

<ParamField path="api_key" type="str" default="None">
  Hathora API key for authentication. Falls back to the `HATHORA_API_KEY`
  environment variable.
</ParamField>

<ParamField
  path="base_url"
  type="str"
  default="https://api.models.hathora.dev/inference/v1/stt"
>
  Base API URL for the Hathora STT service.
</ParamField>

<ParamField path="sample_rate" type="int" default="None">
  Audio sample rate in Hz. When `None`, uses the pipeline's configured sample
  rate.
</ParamField>

<ParamField path="params" type="InputParams" default="None">
  Optional configuration parameters. See [InputParams](#inputparams) below.
</ParamField>

### InputParams

| Parameter  | Type                 | Default | Description                                                                                                                                                                               |
| ---------- | -------------------- | ------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `language` | `str`                | `None`  | Language code, if supported by the selected model.                                                                                                                                        |
| `config`   | `list[ConfigOption]` | `None`  | Additional model-specific configuration options. Refer to [Hathora docs](https://models.hathora.dev) for supported options per model. Each `ConfigOption` has a `name` and `value` field. |

## Usage

### Basic Setup

```python
from pipecat.services.hathora import HathoraSTTService

stt = HathoraSTTService(
    model="your-model-specifier",
    api_key=os.getenv("HATHORA_API_KEY"),
)
```

### With Language and Config Options

```python
from pipecat.services.hathora import HathoraSTTService
from pipecat.services.hathora.utils import ConfigOption

stt = HathoraSTTService(
    model="your-model-specifier",
    api_key=os.getenv("HATHORA_API_KEY"),
    params=HathoraSTTService.InputParams(
        language="en",
        config=[
            ConfigOption(name="option_name", value="option_value"),
        ],
    ),
)
```

## Notes

- **Segmented transcription**: `HathoraSTTService` extends `SegmentedSTTService`, meaning it processes complete audio segments (after VAD detects the user has stopped speaking) rather than streaming audio in real time.
- **Model-specific features**: Configuration options and language support vary by model. Check the [Hathora documentation](https://models.hathora.dev) for details on each model's capabilities.
