---
title: "Fal (Wizper)"
description: "Speech-to-text service implementation using Fal's Wizper API"
---

## Overview

`FalSTTService` provides speech-to-text capabilities using Fal's Wizper API with Voice Activity Detection (VAD) to process only speech segments, optimizing API usage and improving response time for efficient transcription.

<CardGroup cols={2}>
  <Card
    title="Fal STT API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.fal.stt.html"
  >
    Pipecat's API methods for Fal Wizper integration
  </Card>
  <Card
    title="Example Implementation"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/07w-interruptible-fal.py"
  >
    Complete example with VAD integration
  </Card>
  <Card
    title="Fal Documentation"
    icon="book"
    href="https://fal.ai/models/fal-ai/wizper"
  >
    Official Fal Wizper documentation and features
  </Card>
  <Card title="Fal Platform" icon="microphone" href="https://fal.ai/">
    Access API keys and Wizper models
  </Card>
</CardGroup>

## Installation

To use Fal services, install the required dependency:

```bash
pip install "pipecat-ai[fal]"
```

## Prerequisites

### Fal Account Setup

Before using Fal STT services, you need:

1. **Fal Account**: Sign up at [Fal Platform](https://fal.ai/)
2. **API Key**: Generate an API key from your account dashboard
3. **Model Access**: Ensure access to the Wizper transcription model

### Required Environment Variables

- `FAL_KEY`: Your Fal API key for authentication

## Configuration

### FalSTTService

<ParamField path="api_key" type="str" default="None">
  Fal API key. If not provided, uses `FAL_KEY` environment variable.
</ParamField>

<ParamField path="sample_rate" type="int" default="None">
  Audio sample rate in Hz. When `None`, uses the pipeline's configured sample rate.
</ParamField>

<ParamField path="params" type="InputParams" default="None">
  Configuration parameters for the Wizper API. See [InputParams](#inputparams) below.
</ParamField>

<ParamField path="ttfs_p99_latency" type="float" default="FAL_TTFS_P99">
  P99 latency from speech end to final transcript in seconds. Override for your deployment.
</ParamField>

### InputParams

Parameters passed via the `params` constructor argument.

| Parameter | Type | Default | Description |
| --- | --- | --- | --- |
| `language` | `Language` | `Language.EN` | Language of the audio input. |
| `task` | `str` | `"transcribe"` | Task to perform: `"transcribe"` or `"translate"`. |
| `chunk_level` | `str` | `"segment"` | Level of chunking for the response. |
| `version` | `str` | `"3"` | Version of the Wizper model to use. |

## Usage

### Basic Setup

```python
from pipecat.services.fal import FalSTTService

stt = FalSTTService(
    api_key=os.getenv("FAL_KEY"),
)
```

### With Custom Parameters

```python
from pipecat.services.fal import FalSTTService
from pipecat.transcriptions.language import Language

stt = FalSTTService(
    api_key=os.getenv("FAL_KEY"),
    params=FalSTTService.InputParams(
        language=Language.ES,
        task="transcribe",
        version="3",
    ),
)
```

### Translation Mode

```python
stt = FalSTTService(
    api_key=os.getenv("FAL_KEY"),
    params=FalSTTService.InputParams(
        language=Language.FR,
        task="translate",  # Translates to English
    ),
)
```

## Notes

- **Segmented processing**: `FalSTTService` inherits from `SegmentedSTTService`, which buffers audio during speech (detected by VAD) and sends complete segments for transcription. This means it does not provide interim results -- only final transcriptions after each speech segment.
- **Translation support**: Set `task="translate"` to translate audio into English, regardless of the input language.
- **Wizper versions**: The `version` parameter selects the underlying Whisper model version. Version `"3"` is the default and recommended for best accuracy.
