---
title: "Groq (Whisper)"
description: "Speech-to-text service implementation using Groq's Whisper API"
---

## Overview

`GroqSTTService` provides high-accuracy speech recognition using Groq's hosted Whisper API with ultra-fast inference speeds. It uses Voice Activity Detection (VAD) to process speech segments efficiently for optimal performance and accuracy.

<CardGroup cols={2}>
  <Card
    title="Groq STT API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.groq.stt.html"
  >
    Pipecat's API methods for Groq STT integration
  </Card>
  <Card
    title="Example Implementation"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/07l-interruptible-groq.py"
  >
    Complete example with Groq ecosystem integration
  </Card>
  <Card
    title="Groq Documentation"
    icon="book"
    href="https://console.groq.com/docs/api-reference#audio-transcription"
  >
    Official Groq STT documentation and features
  </Card>
  <Card
    title="Groq Console"
    icon="microphone"
    href="https://console.groq.com/keys"
  >
    Access API keys and Whisper models
  </Card>
</CardGroup>

## Installation

To use Groq services, install the required dependency:

```bash
pip install "pipecat-ai[groq]"
```

## Prerequisites

### Groq Account Setup

Before using Groq STT services, you need:

1. **Groq Account**: Sign up at [Groq Console](https://console.groq.com/)
2. **API Key**: Generate an API key from your console dashboard
3. **Model Access**: Ensure access to Whisper transcription models

### Required Environment Variables

- `GROQ_API_KEY`: Your Groq API key for authentication

## Configuration

<ParamField path="model" type="str" default="whisper-large-v3-turbo">
  Whisper model to use for transcription.
</ParamField>

<ParamField path="api_key" type="str" default="None">
  Groq API key. If not provided, uses `GROQ_API_KEY` environment variable.
</ParamField>

<ParamField path="base_url" type="str" default="https://api.groq.com/openai/v1">
  API base URL. Override for custom or proxied deployments.
</ParamField>

<ParamField path="language" type="Language" default="Language.EN">
  Language of the audio input.
</ParamField>

<ParamField path="prompt" type="str" default="None">
  Optional text to guide the model's style or continue a previous segment.
</ParamField>

<ParamField path="temperature" type="float" default="None">
  Sampling temperature between 0 and 1. Lower values are more deterministic.
  Defaults to 0.0.
</ParamField>

<ParamField path="ttfs_p99_latency" type="float" default="GROQ_TTFS_P99">
  P99 latency from speech end to final transcript in seconds. Override for your
  deployment.
</ParamField>

## Usage

### Basic Setup

```python
from pipecat.services.groq import GroqSTTService

stt = GroqSTTService(
    api_key=os.getenv("GROQ_API_KEY"),
)
```

### With Custom Model and Language

```python
from pipecat.services.groq import GroqSTTService
from pipecat.transcriptions.language import Language

stt = GroqSTTService(
    api_key=os.getenv("GROQ_API_KEY"),
    model="whisper-large-v3-turbo",
    language=Language.ES,
)
```

### With Prompt and Temperature

```python
from pipecat.services.groq import GroqSTTService

stt = GroqSTTService(
    api_key=os.getenv("GROQ_API_KEY"),
    prompt="This is a conversation about artificial intelligence and machine learning.",
    temperature=0.0,
)
```

## Notes

- **Segmented processing**: `GroqSTTService` inherits from `SegmentedSTTService` (via `BaseWhisperSTTService`), which buffers audio during speech (detected by VAD) and sends complete segments for transcription. This means it does not provide interim results -- only final transcriptions after each speech segment.
- **Whisper API compatible**: Groq uses the OpenAI-compatible Whisper API format. The service sends audio in WAV format and receives JSON transcription responses.
- **Ultra-fast inference**: Groq's LPU (Language Processing Unit) infrastructure provides significantly faster inference than CPU/GPU-based Whisper deployments, making it suitable for real-time applications despite the segmented processing approach.
- **Prompt guidance**: Use the `prompt` parameter to provide context that helps the model with domain-specific terminology or to maintain consistency across segments.
