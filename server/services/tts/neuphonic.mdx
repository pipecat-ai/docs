---
title: "Neuphonic"
description: "Text-to-speech service implementation using Neuphonicâ€™s API"
---

## Overview

Neuphonic provides high-quality text-to-speech synthesis through two service implementations:

- `NeuphonicTTSService`: WebSocket-based implementation with interruption support
- `NeuphonicHttpTTSService`: HTTP-based implementation for simpler use cases

Both services support various voices, languages, and customization options.

## Installation

To use Neuphonic TTS services, install the required dependencies:

```bash
pip install pipecat-ai[neuphonic]
```

You'll also need to set up your Neuphonic API key as an environment variable: `NEUPHONIC_API_KEY`

## NeuphonicTTSService (WebSocket)

### Configuration

<ParamField path="api_key" type="str" required>
  Your Neuphonic API key
</ParamField>

<ParamField path="voice_id" type="str" default="None">
  Voice identifier to use for synthesis
</ParamField>

<ParamField path="url" type="str" default="wss://api.neuphonic.com">
  Neuphonic WebSocket API endpoint
</ParamField>

<ParamField path="sample_rate" type="int" default="22050">
  Output audio sample rate in Hz
</ParamField>

<ParamField path="encoding" type="str" default="pcm_linear">
  Audio encoding format
</ParamField>

<ParamField path="params" type="InputParams" default="InputParams()">
  Additional configuration parameters
</ParamField>

### InputParams

<ParamField path="language" type="Language" default="Language.EN">
  The language for TTS generation
</ParamField>

<ParamField path="speed" type="float" default="1.0">
  Speech speed multiplier (0.5-2.0)
</ParamField>

## NeuphonicHttpTTSService (HTTP)

### Configuration

<ParamField path="api_key" type="str" required>
  Your Neuphonic API key
</ParamField>

<ParamField path="voice_id" type="str" default="None">
  Voice identifier to use for synthesis
</ParamField>

<ParamField path="url" type="str" default="https://api.neuphonic.com">
  Neuphonic HTTP API endpoint
</ParamField>

<ParamField path="sample_rate" type="int" default="22050">
  Output audio sample rate in Hz
</ParamField>

<ParamField path="encoding" type="str" default="pcm_linear">
  Audio encoding format
</ParamField>

<ParamField path="params" type="InputParams" default="InputParams()">
  Additional configuration parameters (same as WebSocket implementation)
</ParamField>

## Input

Both services accept text input through their TTS pipeline.

## Output Frames

### TTSStartedFrame

Signals the start of audio generation.

### TTSAudioRawFrame

Contains generated audio data:

<ParamField path="audio" type="bytes">
  Raw audio data chunk
</ParamField>

<ParamField path="sample_rate" type="int">
  Audio sample rate (22050Hz default)
</ParamField>

<ParamField path="num_channels" type="int">
  Number of audio channels (1 for mono)
</ParamField>

### TTSStoppedFrame

Signals the completion of audio generation.

### ErrorFrame

Sent when an error occurs during TTS generation:

<ParamField path="error" type="str">
  Error message describing what went wrong
</ParamField>

## Methods

### WebSocket Implementation

The WebSocket implementation (`NeuphonicTTSService`) inherits from `InterruptibleTTSService` and provides:

- Support for interrupting ongoing TTS generation
- Automatic websocket connection management
- Keep-alive mechanism for persistent connections
- Special handling for conversation flows

### HTTP Implementation

The HTTP implementation (`NeuphonicHttpTTSService`) inherits from `TTSService` and provides:

- Simpler API integration using HTTP streaming
- Less overhead for single TTS requests
- Simplified error handling

## Language Support

Neuphonic TTS supports the following languages:

| Language Code | Description | Service Codes |
| ------------- | ----------- | ------------- |
| `Language.EN` | English     | `en`          |
| `Language.ES` | Spanish     | `es`          |
| `Language.DE` | German      | `de`          |
| `Language.NL` | Dutch       | `nl`          |
| `Language.AR` | Arabic      | `ar`          |
| `Language.FR` | French      | `fr`          |
| `Language.PT` | Portugese   | `pt`          |
| `Language.RU` | Ruassian    | `ru`          |
| `Language.HI` | Hindi       | `hi`          |
| `Language.ZH` | Chinese     | `zh`          |

Regional variants (e.g., `EN_US`, `ES_ES`) are automatically mapped to their base language.

## Usage Example

### WebSocket Implementation

```python
from pipecat.services.neuphonic import NeuphonicTTSService
from pipecat.transcriptions.language import Language

# Configure service
tts = NeuphonicTTSService(
    api_key="your-neuphonic-api-key",
    voice_id="preferred-voice-id",
    params=NeuphonicTTSService.InputParams(
        language=Language.EN,
        speed=1.2
    )
)

# Use in pipeline
pipeline = Pipeline([
    ...,
    llm,
    tts,
    transport.output(),
])
```

### HTTP Implementation

```python
from pipecat.services.neuphonic import NeuphonicHttpTTSService
from pipecat.transcriptions.language import Language

# Configure service
tts = NeuphonicHttpTTSService(
    api_key="your-neuphonic-api-key",
    voice_id="preferred-voice-id",
    params=NeuphonicHttpTTSService.InputParams(
        language=Language.ES,
        speed=1.0
    )
)

# Use in pipeline
pipeline = Pipeline([
    ...,
    llm,
    tts,
    transport.output(),
])
```

## Metrics Support

Both services support metrics collection:

- Time to First Byte (TTFB)
- TTS usage metrics
- Processing duration

## Audio Processing

- Configurable sample rate (defaults to 22050Hz)
- PCM linear encoding
- Single channel (mono) output
- Base64 decoding for audio data

## Error Handling

```python
try:
    # Generate speech
    async for frame in service.run_tts(text):
        if isinstance(frame, ErrorFrame):
            handle_error(frame.error)
except Exception as e:
    logger.error(f"TTS error: {e}")
```

## Notes

- WebSocket implementation includes a keep-alive mechanism (10-second interval)
- WebSocket service maintains a persistent connection for faster responses
- Both services automatically select appropriate language codes
- The WebSocket implementation pauses frame processing during speech generation to prevent overlapping responses
