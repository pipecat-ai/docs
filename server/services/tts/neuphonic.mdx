---
title: "Neuphonic"
description: "Text-to-speech service implementation using Neuphonic‚Äôs API"
---

## Overview

Neuphonic provides high-quality text-to-speech synthesis with two implementations:

- `NeuphonicTTSService`: WebSocket-based with real-time streaming and interruption support
- `NeuphonicHttpTTSService`: HTTP-based with server-sent events.

<Tip>
  `NeuphonicTTSService` is the recommended option for interactive applications
  requiring low latency.
</Tip>

<CardGroup cols={3}>
  <Card
    title="API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.neuphonic.tts.html"
  >
    Complete API documentation and method details
  </Card>
  <Card
    title="Neuphonic Docs"
    icon="book"
    href="https://docs.neuphonic.com/api-reference/tts/websocket"
  >
    Official Neuphonic TTS API documentation
  </Card>
  <Card
    title="Example Code"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/07v-interruptible-neuphonic.py"
  >
    Working example with WebSocket streaming
  </Card>
</CardGroup>

## Installation

To use Neuphonic services, install the required dependencies:

```bash
pip install "pipecat-ai[neuphonic]"
```

You'll also need to set up your Neuphonic API key as an environment variable: `NEUPHONIC_API_KEY`.

<Tip>
  Get your API key from the [Neuphonic Console](https://app.neuphonic.com/).
</Tip>

## Frames

### Input

- `TextFrame` - Text content to synthesize into speech
- `TTSSpeakFrame` - Text that should be spoken immediately
- `TTSUpdateSettingsFrame` - Runtime configuration updates (voice, speed, etc.)
- `LLMFullResponseStartFrame` / `LLMFullResponseEndFrame` - LLM response boundaries

### Output

- `TTSStartedFrame` - Signals start of synthesis
- `TTSAudioRawFrame` - Generated audio data chunks (streaming)
- `TTSStoppedFrame` - Signals completion of synthesis
- `ErrorFrame` - API or processing errors

## Service Comparison

| Feature          | NeuphonicTTSService (WebSocket) | NeuphonicHttpTTSService (HTTP) |
| ---------------- | ------------------------------- | ------------------------------ |
| **Streaming**    | ‚úÖ Real-time chunks             | ‚úÖ Server-sent events          |
| **Interruption** | ‚úÖ Advanced handling            | ‚ùå Limited support             |
| **Latency**      | üöÄ Ultra-low                    | üìà Moderate                    |

## Language Support

Neuphonic supports multiple languages with automatic base language detection:

| Language Code | Description | Service Code |
| ------------- | ----------- | ------------ |
| `Language.EN` | English     | `en`         |
| `Language.ES` | Spanish     | `es`         |
| `Language.DE` | German      | `de`         |
| `Language.NL` | Dutch       | `nl`         |
| `Language.AR` | Arabic      | `ar`         |
| `Language.FR` | French      | `fr`         |
| `Language.PT` | Portuguese  | `pt`         |
| `Language.RU` | Russian     | `ru`         |
| `Language.HI` | Hindi       | `hi`         |
| `Language.ZH` | Chinese     | `zh`         |

<Note>
  Regional variants (e.g., `EN_US`, `ES_ES`) are automatically mapped to their
  base language.
</Note>

## Usage Example

### WebSocket Service (Recommended)

Initialize the `NeuphonicTTSService` and use it in a pipeline:

```python
from pipecat.services.neuphonic.tts import NeuphonicTTSService
from pipecat.transcriptions.language import Language
import os

# Configure WebSocket service
tts = NeuphonicTTSService(
    api_key=os.getenv("NEUPHONIC_API_KEY"),
    voice_id="fc854436-2dac-4d21-aa69-ae17b54e98eb",  # Emily voice
    params=NeuphonicTTSService.InputParams(
        language=Language.EN,
        speed=1.2
    ),
    sample_rate=22050
)

# Use in pipeline
pipeline = Pipeline([
    transport.input(),
    stt,
    context_aggregator.user(),
    llm,
    tts,
    transport.output(),
    context_aggregator.assistant()
])
```

### HTTP Service

Initialize the `NeuphonicHttpTTSService` and use it in a pipeline:

```python
from pipecat.services.neuphonic.tts import NeuphonicHttpTTSService

# For simpler, HTTP-based synthesis
http_tts = NeuphonicHttpTTSService(
    api_key=os.getenv("NEUPHONIC_API_KEY"),
    voice_id="your-voice-id",
    params=NeuphonicHttpTTSService.InputParams(
        language=Language.ES,
        speed=1.0
    )
)
```

### Dynamic Voice Switching

```python
from pipecat.frames.frames import TTSUpdateSettingsFrame

# Change voice during conversation
await task.queue_frame(TTSUpdateSettingsFrame({
    "voice_id": "new-voice-id"
}))
```

## Metrics

Both services provide comprehensive metrics:

- **Time to First Byte (TTFB)** - Latency from text input to first audio
- **Processing Duration** - Total synthesis time
- **Character Usage** - Text processed for billing

<Info>
  [Learn how to enable Metrics](/guides/fundamentals/metrics) in your Pipeline.
</Info>

## Additional Notes

- **WebSocket Recommended**: Use `NeuphonicTTSService` for real-time applications requiring low latency and interruption support
