---
title: "Deepgram"
description: "Text-to-speech service implementation using Deepgram's Aura API"
---

## Overview

`DeepgramTTSService` provides high-quality text-to-speech synthesis using Deepgram's Aura API with streaming capabilities and ultra-low latency. The service offers various voice models optimized for conversational AI applications with efficient audio streaming.

<CardGroup cols={2}>
  <Card
    title="Deepgram TTS API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.deepgram.tts.html"
  >
    Pipecat's API methods for Deepgram TTS integration
  </Card>
  <Card
    title="Example Implementation"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/07c-interruptible-deepgram.py"
  >
    Complete example with Silero VAD
  </Card>
  <Card
    title="Deepgram Documentation"
    icon="book"
    href="https://developers.deepgram.com/reference/text-to-speech-api/speak"
  >
    Official Deepgram Aura TTS API documentation
  </Card>
  <Card
    title="Voice Models"
    icon="microphone"
    href="https://developers.deepgram.com/docs/tts-models"
  >
    Browse available Aura voice models
  </Card>
</CardGroup>

## Installation

To use Deepgram services, install the required dependencies:

```bash
pip install "pipecat-ai[deepgram]"
```

## Prerequisites

### Deepgram Account Setup

Before using Deepgram TTS services, you need:

1. **Deepgram Account**: Sign up at [Deepgram Console](https://console.deepgram.com/)
2. **API Key**: Generate an API key from your project dashboard
3. **Voice Selection**: Choose from available Aura voice models

### Required Environment Variables

- `DEEPGRAM_API_KEY`: Your Deepgram API key for authentication

## Configuration

### DeepgramTTSService

<ParamField path="api_key" type="str" required>
  Deepgram API key for authentication.
</ParamField>

<ParamField path="voice" type="str" default="aura-2-helena-en">
  Voice model to use for synthesis.
</ParamField>

<ParamField path="base_url" type="str" default="wss://api.deepgram.com">
  WebSocket base URL for Deepgram API.
</ParamField>

<ParamField path="sample_rate" type="int" default="None">
  Output audio sample rate in Hz. When `None`, uses the pipeline's configured
  sample rate.
</ParamField>

<ParamField path="encoding" type="str" default="linear16">
  Audio encoding format. Must be one of: `"linear16"`, `"mulaw"`, `"alaw"`.
</ParamField>

### DeepgramHttpTTSService

<ParamField path="api_key" type="str" required>
  Deepgram API key for authentication.
</ParamField>

<ParamField path="voice" type="str" default="aura-2-helena-en">
  Voice model to use for synthesis.
</ParamField>

<ParamField path="aiohttp_session" type="aiohttp.ClientSession" required>
  An aiohttp session for HTTP requests. You must create and manage this
  yourself.
</ParamField>

<ParamField path="base_url" type="str" default="https://api.deepgram.com">
  HTTP API base URL.
</ParamField>

<ParamField path="sample_rate" type="int" default="None">
  Output audio sample rate in Hz.
</ParamField>

<ParamField path="encoding" type="str" default="linear16">
  Audio encoding format.
</ParamField>

## Usage

### Basic Setup

```python
from pipecat.services.deepgram import DeepgramTTSService

tts = DeepgramTTSService(
    api_key=os.getenv("DEEPGRAM_API_KEY"),
    voice="aura-2-helena-en",
)
```

### HTTP Service

```python
import aiohttp
from pipecat.services.deepgram import DeepgramHttpTTSService

async with aiohttp.ClientSession() as session:
    tts = DeepgramHttpTTSService(
        api_key=os.getenv("DEEPGRAM_API_KEY"),
        voice="aura-2-helena-en",
        aiohttp_session=session,
    )
```

## Notes

- **WebSocket vs HTTP**: The WebSocket service (`DeepgramTTSService`) supports real-time streaming with interruption handling via the Clear message, making it suitable for interactive conversations. The HTTP service is simpler but processes each request as a batch.
- **Flush behavior**: The WebSocket service automatically flushes pending text when it receives an `LLMFullResponseEndFrame` or `EndFrame`, forcing Deepgram to generate audio for any remaining buffered text.
- **Encoding validation**: The WebSocket service validates the `encoding` parameter at initialization and raises a `ValueError` for unsupported formats.

## Event Handlers

Deepgram TTS supports the standard [service connection events](/server/utilities/service-events):

| Event                 | Description                          |
| --------------------- | ------------------------------------ |
| `on_connected`        | Connected to Deepgram WebSocket      |
| `on_disconnected`     | Disconnected from Deepgram WebSocket |
| `on_connection_error` | WebSocket connection error occurred  |

```python
@tts.event_handler("on_connected")
async def on_connected(service):
    print("Connected to Deepgram")
```
