---
title: "Async"
description: "Text-to-speech services using Async‚Äôs WebSocket and HTTP APIs"
---

## Overview

Async provides two TTS service implementations:

- `AsyncAITTSService`: WebSocket-based streaming TTS with interruption support
- `AsyncAIHttpTTSService`: HTTP-based streaming TTS service for simpler synthesis

<Tip>`AsyncAITTSService` is recommended for real-time applications.</Tip>

<CardGroup cols={3}>
  <Card
    title="API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.asyncai.tts.html"
  >
    Complete API documentation and method details
  </Card>
  <Card
    title="Async Docs"
    icon="book"
    href="https://docs.async.ai/"
  >
    Official Async documentation
  </Card>
  <Card
    title="Example Code"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/07ac-interruptible-asyncai.py"
  >
    Working example with WebSocket streaming and interruption handling
  </Card>
</CardGroup>

## Installation

To use Async services, install the required dependencies:

```bash
pip install "pipecat-ai[asyncai]"
```

You'll also need to set up your Async API key as an environment variable: `ASYNCAI_API_KEY`.

<Tip>
  Get your API key by signing up at
  [async](https://async.ai).
</Tip>

## Frames

### Input

- `TextFrame` - Text content to synthesize into speech
- `TTSSpeakFrame` - Text that the TTS service should speak
- `TTSUpdateSettingsFrame` - Runtime configuration updates (e.g., voice)
- `LLMFullResponseStartFrame` / `LLMFullResponseEndFrame` - LLM response boundaries

### Output

- `TTSStartedFrame` - Signals start of synthesis
- `TTSAudioRawFrame` - Generated audio data chunks
- `TTSStoppedFrame` - Signals completion of synthesis
- `ErrorFrame` - Connection or processing errors

## Service Comparison

| Feature             | AsyncAITTSService (WebSocket) | AsyncAIHttpTTSService (HTTP) |
| ------------------- | ------------------------------ | -----------------------------|
| **Streaming**       | ‚úÖ Low-latency chunks          | ‚úÖ Response streaming         |
| **Interruption**    | ‚úÖ Advanced handling           | ‚ö†Ô∏è Basic support              |
| **Latency**         | üöÄ Low                         | üìà Higher                     |
| **Connection**      | WebSocket persistent           | 	HTTP per-request            |

## Language Support

Async currently supports:

| Language Code | Description        | Service Code |
| ------------- | ------------------ | ------------ |
| `Language.EN` | English            | `en`         |

<Note>
  Async is expanding language support. Check the [official
  documentation](https://docs.async.ai) for the latest available languages.
</Note>

## Usage Example

### WebSocket Service (Recommended)

Initialize the WebSocket service with your API key and desired voice:

```python
from pipecat.services.asyncai.tts import AsyncAITTSService
import os

# Configure WebSocket service
tts = AsyncAITTSService(
    api_key=os.getenv("ASYNCAI_API_KEY"),
    voice_id=os.getenv("ASYNCAI_VOICE_ID"),
    model="asyncflow_v2.0"
)

# Use in pipeline
pipeline = Pipeline([
    transport.input(),
    stt,
    context_aggregator.user(),
    llm,
    tts,
    transport.output(),
    context_aggregator.assistant()
])
```

### HTTP Service

Initialize the `AsyncAIHttpTTSService` and use it in a pipeline:

```python
from pipecat.services.aysncai.tts import AsyncAIHttpTTSService
import aiohttp

# For simpler, non-persistent connections
async with aiohttp.ClientSession() as session:
    http_tts = AsyncAIHttpTTSService(
        api_key=os.getenv("ASYNCAI_API_KEY"),
        voice_id=os.getenv("ASYNCAI_VOICE_ID"),
        aiohttp_session=session,
        model="asyncflow_v2.0"
    )
```

### Dynamic Configuration

Make settings updates by pushing an `TTSUpdateSettingsFrame` for either service:

```python
from pipecat.frames.frames import TTSUpdateSettingsFrame

await task.queue_frame(TTSUpdateSettingsFrame(
    voice_id="new-voice-id",
  )
)
```

## Metrics

Both services provide:

- **Time to First Byte (TTFB)** - Latency from text input to first audio
- **Processing Duration** - Total synthesis time
- **Usage Metrics** - Character count and synthesis statistics

<Info>
  [Learn how to enable Metrics](/guides/features/metrics) in your Pipeline.
</Info>

## Additional Notes

- **WebSocket Recommended**: Use `AsyncAITTSService` for low-latency streaming cases
- **Connection Management**: WebSocket maintains persistent connection with automatic keepalive (10-second intervals)
- **Sample Rate**: Set globally in `PipelineParams` rather than per-service for consistency