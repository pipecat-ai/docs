---
title: "Async"
description: "Text-to-speech services using Async‚Äôs WebSocket and HTTP APIs"
---

## Overview

Async provides two TTS service implementations:

- `AsyncAITTSService`: WebSocket-based streaming TTS with interruption support
- `AsyncAIHttpTTSService`: HTTP-based streaming TTS service for simpler synthesis

<Tip>`AsyncAITTSService` is recommended for real-time applications.</Tip>

<CardGroup cols={3}>
  <Card
    title="API Reference"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.services.asyncai.tts.html"
  >
    Complete API documentation and method details
  </Card>
  <Card title="Async Docs" icon="book" href="https://docs.async.ai/">
    Official Async documentation
  </Card>
  <Card
    title="Example Code"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/07ac-interruptible-asyncai.py"
  >
    Working example with WebSocket streaming and interruption handling
  </Card>
</CardGroup>

## Installation

To use Async services, install the required dependencies:

```bash
pip install "pipecat-ai[asyncai]"
```

You'll also need to set up your Async API key as an environment variable: `ASYNCAI_API_KEY`.

<Tip>Get your API key by signing up at [async](https://async.ai).</Tip>

## Frames

### Input

- `TextFrame` - Text content to synthesize into speech
- `TTSSpeakFrame` - Text that the TTS service should speak
- `TTSUpdateSettingsFrame` - Runtime configuration updates (e.g., voice)
- `LLMFullResponseStartFrame` / `LLMFullResponseEndFrame` - LLM response boundaries

### Output

- `TTSStartedFrame` - Signals start of synthesis
- `TTSAudioRawFrame` - Generated audio data chunks
- `TTSStoppedFrame` - Signals completion of synthesis
- `ErrorFrame` - Connection or processing errors

## Service Comparison

| Feature          | AsyncAITTSService (WebSocket) | AsyncAIHttpTTSService (HTTP) |
| ---------------- | ----------------------------- | ---------------------------- |
| **Streaming**    | ‚úÖ Low-latency chunks         | ‚úÖ Response streaming        |
| **Interruption** | ‚úÖ Advanced handling          | ‚ö†Ô∏è Basic support             |
| **Latency**      | üöÄ Low                        | üìà Higher                    |
| **Connection**   | WebSocket persistent          | HTTP per-request             |

## Language Support

Async currently supports:

| Language Code | Description | Service Code |
| ------------- | ----------- | ------------ |
| `Language.EN` | English     | `en`         |
| `Language.FR` | French      | `fr`         |
| `Language.ES` | Spanish     | `es`         |
| `Language.DE` | German      | `de`         |
| `Language.IT` | Italian     | `it`         |

<Note>
  Language support varies by model. Use multilingual model
  (`asyncflow_multilingual_v1.0`) for language specification.
</Note>
<Note>
  Async is expanding language support. Check the [official
  documentation](https://docs.async.ai) for the latest available languages.
</Note>

## Usage Example

### WebSocket Service (Recommended)

Initialize the WebSocket service with your API key and desired voice:

```python
from pipecat.services.asyncai.tts import AsyncAITTSService
import os

# Configure WebSocket service
tts = AsyncAITTSService(
    api_key=os.getenv("ASYNCAI_API_KEY"),
    voice_id=os.getenv("ASYNCAI_VOICE_ID"),
    model="asyncflow_v2.0"
)

# Use in pipeline
pipeline = Pipeline([
    transport.input(),
    stt,
    context_aggregator.user(),
    llm,
    tts,
    transport.output(),
    context_aggregator.assistant()
])
```

### HTTP Service

Initialize the `AsyncAIHttpTTSService` and use it in a pipeline:

```python
from pipecat.services.aysncai.tts import AsyncAIHttpTTSService
import aiohttp

# For simpler, non-persistent connections
async with aiohttp.ClientSession() as session:
    http_tts = AsyncAIHttpTTSService(
        api_key=os.getenv("ASYNCAI_API_KEY"),
        voice_id=os.getenv("ASYNCAI_VOICE_ID"),
        aiohttp_session=session,
        model="asyncflow_v2.0"
    )
```

### Dynamic Configuration

Make settings updates by pushing an `TTSUpdateSettingsFrame` for either service:

```python
from pipecat.frames.frames import TTSUpdateSettingsFrame

await task.queue_frame(
    TTSUpdateSettingsFrame(settings={"voice": "your-new-voice-id"})
)
```

## Metrics

Both services provide:

- **Time to First Byte (TTFB)** - Latency from text input to first audio
- **Processing Duration** - Total synthesis time
- **Usage Metrics** - Character count and synthesis statistics

<Info>
  [Learn how to enable Metrics](/guides/fundamentals/metrics) in your Pipeline.
</Info>

## Additional Notes

- **WebSocket Recommended**: Use `AsyncAITTSService` for low-latency streaming cases
- **Connection Management**: WebSocket maintains persistent connection with automatic keepalive (10-second intervals)
- **Sample Rate**: Set globally in `PipelineParams` rather than per-service for consistency
