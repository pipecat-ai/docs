---
title: "AWS Nova Sonic"
description: "A real-time, multimodal conversational AI service powered by AWS' Nova Sonic model"
---

The `AWSNovaSonicLLMService` enables natural, real-time conversations with AWS' Nova Sonic model. It provides built-in audio transcription, voice activity detection, and context management for creating interactive AI experiences. It provides:

<CardGroup cols={2}>
  <Card title="Real-time Interaction" icon="video">
    Stream audio and video in real-time with low latency response times
  </Card>

<Card title="Speech Processing" icon="waveform-lines">
  Built-in speech-to-text and text-to-speech capabilities with multiple voice
  options
</Card>

<Card title="Voice Activity Detection" icon="microphone">
  Automatic detection of speech start/stop for natural conversations
</Card>

  <Card title="Context Management" icon="brain">
    Intelligent handling of conversation history and system instructions
  </Card>
</CardGroup>

## Installation

To use `AWSNovaSonicLLMService`, install the required dependencies:

```bash
pip install "pipecat-ai[aws]"
```

You'll also need to set up your AWS credentials as environment variables:

- `AWS_SECRET_ACCESS_KEY`
- `AWS_ACCESS_KEY_ID`
- `AWS_REGION`

## Basic Usage

Hereâ€™s a simple example of setting up a conversational AI bot with AWS Nova Sonic:

```python
from pipecat.services.aws_nova_sonic import AWSNovaSonicLLMService

llm = AWSNovaSonicLLMService(
    secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
    access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
    region=os.getenv("AWS_REGION"),
    voice_id="tiffany"
)
```

## Configuration

### Constructor Parameters

<ParamField path="secret_access_key" type="str" required>
  Your AWS_SECRET_ACCESS_KEY
</ParamField>

<ParamField path="access_key_id" type="str" required>
  Your AWS_ACCESS_KEY_ID
</ParamField>

<ParamField path="region" type="str" required>
  Desired AWS_REGION. Note: as of 2025-05-06, `us-east-1` is the only supported region
</ParamField>

<ParamField path="model" type="str" default="amazon.nova-sonic-v1:0">
  Nova Sonic model to use
</ParamField>

<ParamField path="voice_id" type="str" default="matthew">
  Voice for text-to-speech (options: matthew, tiffany, amy)
</ParamField>

<ParamField path="params" type="Params" default="Params()">
  Generation parameters configuration
</ParamField>

<ParamField path="system_instruction" type="Optional[str]" default="None">
  High-level instructions that guide the model's behavior
</ParamField>

<ParamField path="tools" type="Optional[ToolsSchema]" default="None">
  List of function definitions for the model to use
</ParamField>

<ParamField path="send_transcription_frames" type="bool" default="True">
  Whether to emit transcription frames
</ParamField>

### Params Parameters

<ParamField path="input_sample_rate" type="Optional[int]" default="16000">
  Input sample rate
</ParamField>

<ParamField path="input_sample_size" type="Optional[int]" default="16">
  Input sample size
</ParamField>

<ParamField path="input_channel_count" type="Optional[int]" default="1">
  Input channel count
</ParamField>

<ParamField path="output_sample_rate" type="int" optional default="24000">
  Output sample rate
</ParamField>

<ParamField path="output_sample_size" type="int" optional default="16">
  Output sample size
</ParamField>

<ParamField path="output_channel_count" type="int" optional default="1">
  Output channel count
</ParamField>

<ParamField path="max_tokens" type="int" optional default="1024">
  Maximum number of tokens to generate
</ParamField>

<ParamField path="temperature" type="float" optional default="0.9">
  Controls randomness in responses. Range: 0.0 to 2.0
</ParamField>

<ParamField path="top_p" type="float" optional default="None">
  Cumulative probability cutoff for token selection. Range: 0.0 to 1.0
</ParamField>

## Frame Types

### Input Frames

<ParamField path="InputAudioRawFrame" type="Frame">
  Raw audio data for speech input
</ParamField>

<ParamField path="StartInterruptionFrame" type="Frame">
  Signals start of user interruption
</ParamField>

<ParamField path="UserStartedSpeakingFrame" type="Frame">
  Signals user started speaking
</ParamField>

<ParamField path="UserStoppedSpeakingFrame" type="Frame">
  Signals user stopped speaking
</ParamField>

<ParamField path="OpenAILLMContextFrame" type="Frame">
  Contains conversation context
</ParamField>

### Output Frames

<ParamField path="TTSAudioRawFrame" type="Frame">
  Generated speech audio
</ParamField>

<ParamField path="TTSStartedFrame" type="Frame">
  Signals start of speech synthesis
</ParamField>

<ParamField path="TTSStoppedFrame" type="Frame">
  Signals end of speech synthesis
</ParamField>

<ParamField path="TextFrame" type="Frame">
  Generated text responses
</ParamField>

<ParamField path="TranscriptionFrame" type="Frame">
  Speech transcriptions
</ParamField>

## Function Calling

This service supports function calling (also known as tool calling) which allows the LLM to request information from external services and APIs. For example, you can enable your bot to:

- Check current weather conditions
- Query databases
- Access external APIs
- Perform custom actions

See the [Function Calling guide](/guides/features/function-calling) for:

- Detailed implementation instructions
- Provider-specific function definitions
- Handler registration examples
- Control over function call behavior
- Complete usage examples

## Next Steps

### Usage Examples

- [Foundational Example](https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/39-aws-nova-sonic.py)
  Basic implementation showing core features and function calling

