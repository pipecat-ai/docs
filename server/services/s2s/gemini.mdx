---
title: "Gemini Multimodal Live"
description: "A real-time, multimodal conversational AI service powered by Google’s Gemini"
---

The `GeminiMultimodalLiveLLMService` enables natural, real-time conversations with Google’s Gemini model. It provides built-in audio transcription, voice activity detection, and context management for creating interactive AI experiences. It provides:

<CardGroup cols={2}>
  <Card title="Real-time Interaction" icon="video">
    Stream audio and video in real-time with low latency response times
  </Card>

{" "}

<Card title="Speech Processing" icon="waveform-lines">
  Built-in speech-to-text and text-to-speech capabilities with multiple voice
  options
</Card>

{" "}

<Card title="Voice Activity Detection" icon="microphone">
  Automatic detection of speech start/stop for natural conversations
</Card>

  <Card title="Context Management" icon="brain">
    Intelligent handling of conversation history and system instructions
  </Card>
</CardGroup>

<Tip>
  Want to start building? Check out our [Gemini Multimodal Live
  Guide](/guides/features/gemini-multimodal-live).
</Tip>

## Installation

To use `GeminiMultimodalLiveLLMService`, install the required dependencies:

```bash
pip install pipecat-ai[google]
```

You’ll need to set up your Google API key as an environment variable: `GOOGLE_API_KEY`.

## Basic Usage

Here’s a simple example of setting up a conversational AI bot with Gemini Multimodal Live:

```python
from pipecat.services.gemini_multimodal_live.gemini import GeminiMultimodalLiveLLMService, InputParams

llm = GeminiMultimodalLiveLLMService(
    api_key=os.getenv("GOOGLE_API_KEY"),
    voice_id="Aoede",                    # Voices: Aoede, Charon, Fenrir, Kore, Puck
    transcribe_user_audio=True,          # Enable speech-to-text for user input
    transcribe_model_audio=True,         # Enable speech-to-text for model responses
    params=InputParams(temperature=0.7)  # Set model input params
)
```

## Configuration

### Constructor Parameters

<ParamField path="api_key" type="str" required>
  Your Google API key
</ParamField>

<ParamField
  path="base_url"
  type="str"
  default="preprod-generativelanguage.googleapis.com"
>
  API endpoint URL
</ParamField>

<ParamField path="model" type="str" default="models/gemini-2.0-flash-exp">
  Gemini model to use
</ParamField>

<ParamField path="voice_id" type="str" default="Charon">
  Voice for text-to-speech (options: Aoede, Charon, Fenrir, Kore, Puck)
</ParamField>

```python
llm = GeminiMultimodalLiveLLMService(
    api_key=os.getenv("GOOGLE_API_KEY"),
    voice_id="Puck",  # Choose your preferred voice
)
```

<ParamField path="transcribe_user_audio" type="bool" default="False">
  Enable transcription of user audio
</ParamField>

<ParamField path="transcribe_model_audio" type="bool" default="False">
  Enable transcription of model responses
</ParamField>

```python
llm = GeminiMultimodalLiveLLMService(
    api_key=os.getenv("GOOGLE_API_KEY"),
    transcribe_user_audio=True,   # Log user speech as text
    transcribe_model_audio=True,  # Log model responses as text
)
```

<ParamField path="system_instruction" type="str" optional>
  High-level instructions that guide the model's behavior
</ParamField>

```python
llm = GeminiMultimodalLiveLLMService(
    api_key=os.getenv("GOOGLE_API_KEY"),
    system_instruction="Talk like a pirate.",
)
```

### Input Parameters

<ParamField path="frequency_penalty" type="float" optional default="None">
  Penalizes repeated tokens. Range: 0.0 to 2.0
</ParamField>

<ParamField path="max_tokens" type="int" optional default="4096">
  Maximum number of tokens to generate
</ParamField>

<ParamField path="presence_penalty" type="float" optional default="None">
  Penalizes tokens based on their presence in the text. Range: 0.0 to 2.0
</ParamField>

<ParamField path="temperature" type="float" optional default="None">
  Controls randomness in responses. Range: 0.0 to 2.0
</ParamField>

```python
llm = GeminiMultimodalLiveLLMService(
    api_key=os.getenv("GOOGLE_API_KEY"),
    params=InputParams(
        temperature=0.7,  # More creative responses
    )
)
```

<ParamField path="top_k" type="int" optional default="None">
  Limits vocabulary to k most likely tokens. Minimum: 0
</ParamField>

<ParamField path="top_p" type="float" optional default="None">
  Cumulative probability cutoff for token selection. Range: 0.0 to 1.0
</ParamField>

```python
llm = GeminiMultimodalLiveLLMService(
    api_key=os.getenv("GOOGLE_API_KEY"),
    params=InputParams(
        top_p=0.9,     # More focused token selection
        top_k=40       # Limit vocabulary options
    )
)
```

## Frame Types

### Input Frames

<ParamField path="InputAudioRawFrame" type="Frame">
  Raw audio data for speech input
</ParamField>

<ParamField path="StartInterruptionFrame" type="Frame">
  Signals start of user interruption
</ParamField>

<ParamField path="UserStartedSpeakingFrame" type="Frame">
  Signals user started speaking
</ParamField>

<ParamField path="UserStoppedSpeakingFrame" type="Frame">
  Signals user stopped speaking
</ParamField>

<ParamField path="OpenAILLMContextFrame" type="Frame">
  Contains conversation context
</ParamField>

### Output Frames

<ParamField path="TTSAudioRawFrame" type="Frame">
  Generated speech audio
</ParamField>

<ParamField path="TTSStartedFrame" type="Frame">
  Signals start of speech synthesis
</ParamField>

<ParamField path="TTSStoppedFrame" type="Frame">
  Signals end of speech synthesis
</ParamField>

<ParamField path="TextFrame" type="Frame">
  Generated text responses
</ParamField>

<ParamField path="TranscriptionFrame" type="Frame">
  Speech transcriptions
</ParamField>

## Next Steps

### Examples

- [Foundational Example](https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/26a-gemini-multimodal-live-transcription.py)
  Basic implementation showing core features and transcription

- [Simple Chatbot](https://github.com/pipecat-ai/pipecat/tree/main/examples/simple-chatbot)
  A client/server example showing how to build a Pipecat JS or React client that connects to a Gemini Live Pipecat bot.

### Learn More

Check out our [Gemini Multimodal Live Guide](/guides/features/gemini-live) for detailed explanations and best practices.
