---
title: "Gemini Multimodal Live"
description: "A real-time, multimodal conversational AI service powered by Google’s Gemini"
---

The `GeminiMultimodalLiveLLMService` enables natural, real-time conversations with Google’s Gemini model. It provides built-in audio transcription, voice activity detection, and context management for creating interactive AI experiences. It provides:

<CardGroup cols={2}>
  <Card title="Real-time Interaction" icon="video">
    Stream audio and video in real-time with low latency response times
  </Card>

<Card title="Speech Processing" icon="waveform-lines">
  Built-in speech-to-text and text-to-speech capabilities with multiple voice
  options
</Card>

<Card title="Voice Activity Detection" icon="microphone">
  Automatic detection of speech start/stop for natural conversations
</Card>

  <Card title="Context Management" icon="brain">
    Intelligent handling of conversation history and system instructions
  </Card>
</CardGroup>

<Tip>
  Want to start building? Check out our [Gemini Multimodal Live
  Guide](/guides/features/gemini-multimodal-live).
</Tip>

## Installation

To use `GeminiMultimodalLiveLLMService`, install the required dependencies:

```bash
pip install "pipecat-ai[google]"
```

You’ll need to set up your Google API key as an environment variable: `GOOGLE_API_KEY`.

## Basic Usage

Here’s a simple example of setting up a conversational AI bot with Gemini Multimodal Live:

```python
from pipecat.services.gemini_multimodal_live.gemini import (
    GeminiMultimodalLiveLLMService,
    InputParams,
    GeminiMultimodalModalities
)

llm = GeminiMultimodalLiveLLMService(
    api_key=os.getenv("GOOGLE_API_KEY"),
    voice_id="Aoede",                    # Voices: Aoede, Charon, Fenrir, Kore, Puck
    transcribe_user_audio=True,          # Enable speech-to-text for user input
    params=InputParams(
        temperature=0.7,                 # Set model input params
        language=Language.EN_US,         # Set language (30+ languages supported)
        modalities=GeminiMultimodalModalities.AUDIO  # Response modality
    )
)
```

## Configuration

### Constructor Parameters

<ParamField path="api_key" type="str" required>
  Your Google API key
</ParamField>

<ParamField
  path="base_url"
  type="str"
  default="generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1beta.GenerativeService.BidiGenerateContent"
>
  API endpoint URL
</ParamField>

<ParamField path="model" type="str" default="models/gemini-2.0-flash-live-001">
  Gemini model to use (upgraded to new v1beta model)
</ParamField>

<ParamField path="voice_id" type="str" default="Charon">
  Voice for text-to-speech (options: Aoede, Charon, Fenrir, Kore, Puck)
</ParamField>

```python
llm = GeminiMultimodalLiveLLMService(
    api_key=os.getenv("GOOGLE_API_KEY"),
    voice_id="Puck",  # Choose your preferred voice
)
```

<ParamField path="transcribe_user_audio" type="bool" default="False">
  Enable transcription of user audio
</ParamField>

<ParamField path="system_instruction" type="str" optional>
  High-level instructions that guide the model's behavior
</ParamField>

```python
llm = GeminiMultimodalLiveLLMService(
    api_key=os.getenv("GOOGLE_API_KEY"),
    system_instruction="Talk like a pirate.",
)
```

### Input Parameters

<ParamField path="frequency_penalty" type="float" optional default="None">
  Penalizes repeated tokens. Range: 0.0 to 2.0
</ParamField>

<ParamField path="max_tokens" type="int" optional default="4096">
  Maximum number of tokens to generate
</ParamField>

<ParamField
  path="modalities"
  type="GeminiMultimodalModalities"
  optional
  default="AUDIO"
>
  Response modalities to include (options: `AUDIO`, `TEXT`).
</ParamField>

<ParamField path="presence_penalty" type="float" optional default="None">
  Penalizes tokens based on their presence in the text. Range: 0.0 to 2.0
</ParamField>

<ParamField path="temperature" type="float" optional default="None">
  Controls randomness in responses. Range: 0.0 to 2.0
</ParamField>

<ParamField path="language" type="Language" optional default="Language.EN_US">
  Language for generation. Over 30 languages are supported.
</ParamField>

<ParamField
  path="media_resolution"
  type="GeminiMediaResolution"
  optional
  default="UNSPECIFIED"
>
  
Controls image processing quality and token usage:

- `LOW`: Uses 64 tokens
- `MEDIUM`: Uses 256 tokens
- `HIGH`: Zoomed reframing with 256 tokens

</ParamField>

<ParamField path="vad" type="GeminiVADParams" optional>

Voice Activity Detection configuration:

- `disabled`: Toggle VAD on/off
- `start_sensitivity`: How quickly speech is detected (HIGH/LOW)
- `end_sensitivity`: How quickly turns end after pauses (HIGH/LOW)
- `prefix_padding_ms`: Milliseconds of audio to keep before speech
- `silence_duration_ms`: Milliseconds of silence to end a turn

</ParamField>

```python
from pipecat.services.gemini_multimodal_live.gemini import (
    GeminiVADParams,
    GeminiMediaResolution,
    StartSensitivity,
    EndSensitivity
)

llm = GeminiMultimodalLiveLLMService(
    api_key=os.getenv("GOOGLE_API_KEY"),
    params=InputParams(
        temperature=0.7,
        language=Language.ES,  # Spanish language
        media_resolution=GeminiMediaResolution.HIGH,  # Higher quality image processing
        vad=GeminiVADParams(
            start_sensitivity=StartSensitivity.HIGH,  # Detect speech quickly
            end_sensitivity=EndSensitivity.LOW,      # Allow longer pauses
            prefix_padding_ms=300,                   # Keep 300ms before speech
            silence_duration_ms=1000,                # End turn after 1s silence
        )
    )
)
```

<ParamField path="top_k" type="int" optional default="None">
  Limits vocabulary to k most likely tokens. Minimum: 0
</ParamField>

<ParamField path="top_p" type="float" optional default="None">
  Cumulative probability cutoff for token selection. Range: 0.0 to 1.0
</ParamField>

```python
llm = GeminiMultimodalLiveLLMService(
    api_key=os.getenv("GOOGLE_API_KEY"),
    params=InputParams(
        top_p=0.9,     # More focused token selection
        top_k=40       # Limit vocabulary options
    )
)
```

## Frame Types

### Input Frames

<ParamField path="InputAudioRawFrame" type="Frame">
  Raw audio data for speech input
</ParamField>

<ParamField path="StartInterruptionFrame" type="Frame">
  Signals start of user interruption
</ParamField>

<ParamField path="UserStartedSpeakingFrame" type="Frame">
  Signals user started speaking
</ParamField>

<ParamField path="UserStoppedSpeakingFrame" type="Frame">
  Signals user stopped speaking
</ParamField>

<ParamField path="OpenAILLMContextFrame" type="Frame">
  Contains conversation context
</ParamField>

### Output Frames

<ParamField path="TTSAudioRawFrame" type="Frame">
  Generated speech audio
</ParamField>

<ParamField path="TTSStartedFrame" type="Frame">
  Signals start of speech synthesis
</ParamField>

<ParamField path="TTSStoppedFrame" type="Frame">
  Signals end of speech synthesis
</ParamField>

<ParamField path="TextFrame" type="Frame">
  Generated text responses
</ParamField>

<ParamField path="TranscriptionFrame" type="Frame">
  Speech transcriptions
</ParamField>

## Function Calling

This service supports function calling (also known as tool calling) which allows the LLM to request information from external services and APIs. For example, you can enable your bot to:

- Check current weather conditions
- Query databases
- Access external APIs
- Perform custom actions

See the [Function Calling guide](/guides/fundamentals/function-calling) for:

- Detailed implementation instructions
- Provider-specific function definitions
- Handler registration examples
- Control over function call behavior
- Complete usage examples

## Language Support

Gemini Multimodal Live supports the following languages:

| Language Code     | Description          | Gemini Code |
| ----------------- | -------------------- | ----------- |
| `Language.AR`     | Arabic               | `ar-XA`     |
| `Language.BN_IN`  | Bengali (India)      | `bn-IN`     |
| `Language.CMN_CN` | Chinese (Mandarin)   | `cmn-CN`    |
| `Language.DE_DE`  | German (Germany)     | `de-DE`     |
| `Language.EN_US`  | English (US)         | `en-US`     |
| `Language.EN_AU`  | English (Australia)  | `en-AU`     |
| `Language.EN_GB`  | English (UK)         | `en-GB`     |
| `Language.EN_IN`  | English (India)      | `en-IN`     |
| `Language.ES_ES`  | Spanish (Spain)      | `es-ES`     |
| `Language.ES_US`  | Spanish (US)         | `es-US`     |
| `Language.FR_FR`  | French (France)      | `fr-FR`     |
| `Language.FR_CA`  | French (Canada)      | `fr-CA`     |
| `Language.GU_IN`  | Gujarati (India)     | `gu-IN`     |
| `Language.HI_IN`  | Hindi (India)        | `hi-IN`     |
| `Language.ID_ID`  | Indonesian           | `id-ID`     |
| `Language.IT_IT`  | Italian (Italy)      | `it-IT`     |
| `Language.JA_JP`  | Japanese (Japan)     | `ja-JP`     |
| `Language.KN_IN`  | Kannada (India)      | `kn-IN`     |
| `Language.KO_KR`  | Korean (Korea)       | `ko-KR`     |
| `Language.ML_IN`  | Malayalam (India)    | `ml-IN`     |
| `Language.MR_IN`  | Marathi (India)      | `mr-IN`     |
| `Language.NL_NL`  | Dutch (Netherlands)  | `nl-NL`     |
| `Language.PL_PL`  | Polish (Poland)      | `pl-PL`     |
| `Language.PT_BR`  | Portuguese (Brazil)  | `pt-BR`     |
| `Language.RU_RU`  | Russian (Russia)     | `ru-RU`     |
| `Language.TA_IN`  | Tamil (India)        | `ta-IN`     |
| `Language.TE_IN`  | Telugu (India)       | `te-IN`     |
| `Language.TH_TH`  | Thai (Thailand)      | `th-TH`     |
| `Language.TR_TR`  | Turkish (Turkey)     | `tr-TR`     |
| `Language.VI_VN`  | Vietnamese (Vietnam) | `vi-VN`     |

You can set the language using the `language` parameter:

```python
from pipecat.transcriptions.language import Language
from pipecat.services.gemini_multimodal_live.gemini import (
    GeminiMultimodalLiveLLMService,
    InputParams
)

# Set language during initialization
llm = GeminiMultimodalLiveLLMService(
    api_key=os.getenv("GOOGLE_API_KEY"),
    params=InputParams(language=Language.ES_ES)  # Spanish (Spain)
)
```

## Next Steps

### Examples

- [Foundational Example](https://github.com/pipecat-ai/pipecat/blob/main/examples/foundational/26a-gemini-multimodal-live-transcription.py)
  Basic implementation showing core features and transcription

- [Simple Chatbot](https://github.com/pipecat-ai/pipecat/tree/main/examples/simple-chatbot)
  A client/server example showing how to build a Pipecat JS or React client that connects to a Gemini Live Pipecat bot.

### Learn More

Check out our [Gemini Multimodal Live Guide](/guides/features/gemini-multimodal-live) for detailed explanations and best practices.
