---
title: "Server API Reference"
description: "Complete reference for Pipecatâ€™s Python server APIs and services"
---

## Overview

Pipecat's server-side functionality is organized into three main categories:

<CardGroup cols={3}>
  <Card
    title="Services"
    icon="puzzle-piece"
  >
    AI service integrations for speech, language, vision, and more
  </Card>
  <Card title="Frameworks" icon="puzzle">
    > User RTVI for client/server communication or Pipecat Flows for building structured conversations
  </Card>

  <Card title="Utilities" icon="wrench">
    Helper functions and tools for audio, filtering, and flows
  </Card>
</CardGroup>

## Service Categories

Pipecat integrates with various AI services across different categories:

<CardGroup cols={2}>
  <Card title="Transport" icon="network-wired">
    WebRTC and WebSocket implementations for real-time communication
  </Card>
  <Card title="Speech Processing" icon="waveform-lines">
    Speech-to-text, text-to-speech, and speech-to-speech services
  </Card>
  <Card title="Language Models" icon="brain">
    Integration with various LLM providers
  </Card>
  <Card title="Vision & Media" icon="image">
    Image generation, video processing, and computer vision
  </Card>
</CardGroup>

## Getting Started

1. Browse our [Supported Services](/server/services/supported-services) to see available integrations
2. Install required dependencies for your chosen services
3. Reference individual service docs for detailed configuration options

## Example Usage

```python
from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.pipeline import Pipeline
from pipecat.processors.aggregators.openai_llm_context import OpenAILLMContext
from pipecat.services.cartesia.tts import CartesiaTTSService
from pipecat.services.deepgram.stt import DeepgramSTTService
from pipecat.services.openai.llm import OpenAILLMService
from pipecat.transports.daily.transport import DailyParams, DailyTransport

transport = DailyTransport(
    room_url,
    token,
    "Respond bot",
    DailyParams(
        audio_in_enabled=True,
        audio_out_enabled=True,
        vad_analyzer=SileroVADAnalyzer(),
    ),
)

# Configure services
stt = DeepgramSTTService(api_key=KEY)
llm = OpenAILLMService(api_key=KEY, model="gpt-4o")
tts = CartesiaTTSService(api_key=KEY, voice_id=ID)

# Create context and aggregators
context = OpenAILLMContext(
    messages=[{"role": "system", "content": "You are a helpful assistant."}]
)
context_aggregator = llm.create_context_aggregator(context)

# Create pipeline
pipeline = Pipeline([
    transport.input(),
    stt,
    context_aggregator.user(),
    llm,
    tts,
    transport.output(),
    context_aggregator,assistant()
])
```
