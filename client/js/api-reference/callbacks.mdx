---
title: "Callbacks and events"
---

import { callbacks, TransportTable } from "/snippets/js-transport-support.jsx";

The Pipecat JavaScript client listens for messages and events from the bot via the transport layer. This allows you to respond to changes in state, errors, and other events. The client implements the RTVI standard for these communications.

## Event Handling Options

You can handle events in two ways:

### 1. Callbacks

Define handlers in the client constructor:

```typescript
const pcClient = new PipecatClient({
  callbacks: {
    onBotReady: () => console.log("Bot ready via callback"),
    // ... other callbacks
  },
});
```

### 2. Event Listeners

Add handlers using the event emitter pattern:

```typescript
pcClient.on(RTVIEvent.BotReady, () => console.log("Bot ready via event"));
```

<Note>
  Events and callbacks provide the same functionality. Choose the pattern that
  best fits your application's architecture.
</Note>

## Callbacks

### State and connectivity

<ParamField path="onConnected">
  Local user successfully established a connection to the transport.
</ParamField>

<ParamField path="onDisconnected">
  Local user disconnected from the transport, either intentionally by calling
  `pcClient.disconnect()` or due to an error.
</ParamField>

<ParamField path="onTransportStateChanged" type="state:TransportState">
  Provides a `TransportState` string representing the connectivity state of the
  local client. See [transports](./transports) for state explanation.
</ParamField>

<ParamField path="onBotStarted" type="botResponse: unknown">
  A call to [`startBot()`](./client-methods#startbot) (i.e. a pre-connection REST endpoint) was successful and the bot should now be started or in the process of starting. The callback receives any data returned from your endpoint.
</ParamField>

<ParamField path="onBotReady" type="botReadyData:BotReadyData">
  The bot has been instantiated, its pipeline is configured, and it is receiving
  user media and interactions. This method is passed a `BotReadyData` object,
  which contains the RTVI `version` number. Since the bot is remote and may be
  using a different version of RTVI than the client, you can use the passed
  `version` string to check for compatibility.
</ParamField>

<ParamField path="onBotConnected">
  Bot connected to the transport and is configuring. Note: bot connectivity does
  not infer that its pipeline is yet ready to run. Please use `onBotReady`
  instead.
</ParamField>

<ParamField path="onBotDisconnected" type="participant: Participant">
  Bot disconnected from the transport. This may occur due to session expiry, a
  pipeline error or for any reason the server deems the session over.
</ParamField>

<ParamField path="onParticipantJoined" type="participant: Participant">
  A non-bot participant joined the session.
</ParamField>

<ParamField path="onParticipantLeft" type="participant: Participant">
  A non-bot participant left the session. Note: excluded local participant.
</ParamField>

### Messages and errors

<ParamField path="onServerMessage" type="data:any">
  Receives custom messages sent from the server to the client. This provides a
  generic channel for server-to-client communication. The data structure is
  flexible and defined by the server implementation.
</ParamField>

<ParamField path="onMessageError" type="message:RTVIMessage">
  Response error when an action fails or an unknown message type is sent from
  the client.
</ParamField>

<ParamField path="onError" type="message:RTVIMessage">
  Error signalled by the bot. This could be due to a malformed config update or
  an unknown action dispatch or the inability to complete a client request. The
  message parameter is of type `error` and matches [the RTVI
  standard](/client/rtvi-standard#error-%F0%9F%A4%96). Its `data` field includes
  a `message` string that describes the error and a `fatal` boolean indicating
  if the error is unrecoverable and resulted in a bot disconnection. If `fatal`
  is true, the client will automatically disconnect.
</ParamField>

### Media and devices

<ParamField path="onAvailableMicsUpdated" type="mics:MediaDeviceInfo[]">
  Lists available local media microphone devices. Triggered when a new device
  becomes available, a device is removed, or in response to
  `pcClient.initDevices()`.
</ParamField>

<ParamField path="onAvailableCamsUpdated" type="cams:MediaDeviceInfo[]">
  Lists available local media camera devices. Triggered when a new device
  becomes available, a device is removed, or in response to
  `pcClient.initDevices()`.
</ParamField>

<ParamField path="onAvailableSpeakersUpdated" type="speakers:MediaDeviceInfo[]">
  Lists available local speaker devices. Triggered when a new device becomes
  available, a device is removed, or in response to `pcClient.initDevices()`.
</ParamField>

<ParamField path="onMicUpdated" type="mic:MediaDeviceInfo">
  User selected a new microphone as their selected/active device.
</ParamField>

<ParamField path="onCamUpdated" type="cam:MediaDeviceInfo">
  User selected a new camera as their selected/active device.
</ParamField>

<ParamField path="onSpeakerUpdated" type="speaker:MediaDeviceInfo">
  User selected a new speaker as their selected/active device.
</ParamField>

<ParamField path="onDeviceError" type="error:DeviceError">
  Error related to media devices, such as camera or microphone issues. This
  could be due to permissions, device unavailability, or other related problems.
  See the [DeviceError](errors#deviceerror) section for more details about the
  return type.
</ParamField>

<ParamField
  path="onTrackStarted"
  type="track: MediaStreamTrack, participant:Participant"
>
  Media track from a local or remote participant/bot was started and playable.
  Can be either an audio or video track.
</ParamField>

<ParamField
  path="onTrackStopped"
  type="track: MediaStreamTrack, participant:Participant"
>
  Media track from a local or remote participant/bot was stopped and no longer
  playable.
</ParamField>

<ParamField
  path="onScreenTrackStarted"
  type="track: MediaStreamTrack, participant:Participant"
>
  Media track from a local or remote participant's screenshare was started and
  playable. Can be either an audio or video track.
</ParamField>

<ParamField
  path="onScreenTrackStopped"
  type="track: MediaStreamTrack, participant:Participant"
>
  Media track from a local or remote participant's screenshare was stopped and
  no longer playable.
</ParamField>

### Audio and Voice Activity

<ParamField path="onLocalAudioLevel" type="level:number">
  Local audio gain level (0 to 1).
</ParamField>

<ParamField
  path="onRemoteAudioLevel"
  type="level: number, participant: Participant"
>
  Remote audio gain level (0 to 1). Note: if more than one participant is
  connected to the transport, the `participant` property details the associated
  peer/bot.
</ParamField>

<ParamField path="onBotStartedSpeaking">
  The bot started speaking/sending speech audio.
</ParamField>

<ParamField path="onBotStoppedSpeaking">
  The bot stopped speaking/sending speech audio.
</ParamField>

<ParamField path="onUserStartedSpeaking">
  The local user started speaking. This method is more reliable than using audio
  gain and is the result of the bot's VAD (voice activity detection) model. This
  provides a more accurate result in noisy environments.
</ParamField>

<ParamField path="onUserStoppedSpeaking">
  The local user stopped speaking, indicated by the VAD model.
</ParamField>

### Transcription

<ParamField path="onUserTranscript" type="TranscriptData">
  Transcribed local user input (both partial and final).

Callback receives a `TranscriptData` object:

  <Expandable title="TranscriptData">
    <ParamField path="text" type="string">
      The transcribed text.
    </ParamField>
    <ParamField path="final" type="boolean">
      Indicates if the text is final (true) or partial (false).
    </ParamField>
    <ParamField path="timestamp" type="string">
      The timestamp of the transcription.
    </ParamField>
    <ParamField path="user_id" type="string">
      The ID of the user the transcription is for.
    </ParamField>
  </Expandable>
</ParamField>

<ParamField path="onBotTranscript" type="text:BotLLMTextData">
  Finalized bot output text generated by the LLM. Sentence aggregated.
</ParamField>

### Service-specific Events

<ParamField path="onBotLlmSearchResponse" type="BotLLMSearchResponseData">
  Bot LLM search response text generated by the LLM service. This is typically
  used for search or retrieval tasks.
  <Warning>
    Search capabilities are currently only supported by Google Gemini. To take
    advantage of this event, your pipeline must include a
    [`GoogleLLMService`](/server/services/llm/gemini) and your pipeline task
    should include the
    [`GoogleRTVIObserver`](/server/frameworks/rtvi/google-rtvi-observer) in lieu
    of the typical `RTVIObserver`.
  </Warning>
  <Expandable title="BotLLMSearchResponseData">
    <ParamField path="search_result" type="string">
      The search result text.
    </ParamField>
    <ParamField path="rendered_content" type="string">
      The rendered content of the search result.
    </ParamField>
    <ParamField path="origins" type="LLMSearchOrigin[]">
      The origins of the search result.
      <Expandable title="LLMSearchOrigin">
        <ParamField path="site_uri" type="string">
          The URI of the site where the search result was found.
        </ParamField>
        <ParamField path="site_title" type="string">
          The title of the site where the search result was found.
        </ParamField>
        <ParamField path="results" type="LLMSearchResult[]">
          The individual search results.
          <Expandable title="LLMSearchResult">
            <ParamField path="text" type="string">
              The text of the search result.
            </ParamField>
            <ParamField path="confidence" type="number[]">
              The confidence scores for the search result.
            </ParamField>
          </Expandable>
        </ParamField>
      </Expandable>
    </ParamField>
  </Expandable>
</ParamField>

<ParamField path="onBotLlmText" type="BotLLMTextData">
  Streamed LLM token response text generated by the LLM service.
  <Expandable title="BotLLMTextData">
    <ParamField path="text" type="string">
      The text of the LLM response.
    </ParamField>
  </Expandable>
</ParamField>

<ParamField path="onBotLlmStarted">LLM service inference started.</ParamField>

<ParamField path="onBotLlmStopped">LLM service inference concluded.</ParamField>

<ParamField path="onBotTtsText" type="BotTTSTextData">
  If your TTS service supports streamed responses over sockets, the text
  parameter contains the words from TTS service as they are spoken. If you are
  using a HTTP based TTS service, the text parameter will contain the full text
  of the TTS response.
  <Expandable title="BotTTSTextData" defaultOpen="true">
    <ParamField path="text" type="string">
      The text of the LLM response.
    </ParamField>
  </Expandable>
</ParamField>

<ParamField path="onBotTtsStarted">TTS service started inference.</ParamField>

<ParamField path="onBotTtsStopped">TTS service inference concluded.</ParamField>

### Other

<ParamField path="onMetrics" default="data:PipecatMetricsData">
  Pipeline mterics data provided by Pipecat. [Learn
  more](/guides/fundamentals/metrics).
</ParamField>

## Events

Each callback described above has a corresponding event that can be listened for using the `.on()` method. This allows you to handle the same functionality using either callbacks or event listeners, depending on your preferred architecture.

Here's the complete reference mapping events to their corresponding callbacks:

### State and connectivity Events

| Event Name              | Callback Name             | Data Type        |
| ----------------------- | ------------------------- | ---------------- |
| `Connected`             | `onConnected`             | -                |
| `Disconnected`          | `onDisconnected`          | -                |
| `TransportStateChanged` | `onTransportStateChanged` | `TransportState` |
| `BotReady`              | `onBotReady`              | `BotReadyData`   |
| `BotConnected`          | `onBotConnected`          | -                |
| `BotDisconnected`       | `onBotDisconnected`       | `Participant`    |
| `ParticipantConnected`  | `onParticipantJoined`     | `Participant`    |
| `ParticipantLeft`       | `onParticipantLeft`       | `Participant`    |

### Message and Error Events

| Event Name      | Callback Name     | Data Type     |
| --------------- | ----------------- | ------------- |
| `ServerMessage` | `onServerMessage` | `any`         |
| `MessageError`  | `onMessageError`  | `RTVIMessage` |
| `Error`         | `onError`         | `RTVIMessage` |

### Media Events

| Event Name             | Callback Name            | Data Type                       |
| ---------------------- | ------------------------ | ------------------------------- |
| `TrackStarted`         | `onTrackStarted`         | `MediaStreamTrack, Participant` |
| `TrackStopped`         | `onTrackStopped`         | `MediaStreamTrack, Participant` |
| `AvailableMicsUpdated` | `onAvailableMicsUpdated` | `MediaDeviceInfo[]`             |
| `AvailableCamsUpdated` | `onAvailableCamsUpdated` | `MediaDeviceInfo[]`             |
| `MicUpdated`           | `onMicUpdated`           | `MediaDeviceInfo`               |
| `CamUpdated`           | `onCamUpdated`           | `MediaDeviceInfo`               |
| `SpeakerUpdated`       | `onSpeakerUpdated`       | `MediaDeviceInfo`               |
| `DeviceError`          | `onDeviceError`          | `DeviceError`                   |

### Audio Activity Events

| Event Name            | Callback Name           | Data Type             |
| --------------------- | ----------------------- | --------------------- |
| `LocalAudioLevel`     | `onLocalAudioLevel`     | `number`              |
| `RemoteAudioLevel`    | `onRemoteAudioLevel`    | `number, Participant` |
| `BotStartedSpeaking`  | `onBotStartedSpeaking`  | -                     |
| `BotStoppedSpeaking`  | `onBotStoppedSpeaking`  | -                     |
| `UserStartedSpeaking` | `onUserStartedSpeaking` | -                     |
| `UserStoppedSpeaking` | `onUserStoppedSpeaking` | -                     |

### Text and Transcription Events

| Event Name       | Callback Name      | Data Type        |
| ---------------- | ------------------ | ---------------- |
| `UserTranscript` | `onUserTranscript` | `TranscriptData` |
| `BotTranscript`  | `onBotTranscript`  | `BotLLMTextData` |
| `BotLlmText`     | `onBotLlmText`     | `BotLLMTextData` |
| `BotTtsText`     | `onBotTtsText`     | `BotTTSTextData` |

### Service State Events

| Event Name             | Callback Name            | Data Type                  |
| ---------------------- | ------------------------ | -------------------------- |
| `BotLlmSearchResponse` | `onBotLlmSearchResponse` | `BotLLMSearchResponseData` |
| `BotLlmStarted`        | `onBotLlmStarted`        | -                          |
| `BotLlmStopped`        | `onBotLlmStopped`        | -                          |
| `BotTtsStarted`        | `onBotTtsStarted`        | -                          |
| `BotTtsStopped`        | `onBotTtsStopped`        | -                          |

### Other Events

| Event Name | Callback Name | Data Type            |
| ---------- | ------------- | -------------------- |
| `Metrics`  | `onMetrics`   | `PipecatMetricsData` |

## Usage Example

```typescript
import { PipecatClient, RTVIEvent } from "@pipecat-ai/client-js";

// Using callbacks
const pcClient = new PipecatClient({
  callbacks: {
    onBotReady: () => console.log("Bot ready via callback"),
    onUserTranscript: (data) => console.log("Transcript:", data.text),
  },
});

// Alternate approach: Using event listeners
pcClient.on(RTVIEvent.BotReady, () => {
  console.log("Bot ready via event");
});
```

## Transport Compatibility

<TransportTable rows={callbacks()} />
